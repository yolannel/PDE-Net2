{'--name': 'burgers-2-upwind-sparse0.005-noise0.001', '--dtype': 'double', '--device': 'cuda:0', '--constraint': '2', '--dt': 0.01, '--cell_num': 1, '--eps': 6.283185307179586, '--blocks': [0, 1, 2, 3, 4, 5, 6, 9, 12, 15, 18], '--kernel_size': 5, '--max_order': 2, '--dx': 0.19634954084936207, '--hidden_layers': 3, '--scheme': 'upwind', '--dataname': 'burgers', '--viscosity': 0.05, '--zoom': 4, '--max_dt': 0.000625, '--batch_size': 28, '--data_timescheme': 'rk2', '--channel_names': 'u,v', '--freq': 4, '--data_start_time': 1.0, '--start_noise': 0.001, '--end_noise': 0.001, '--stablize': 0.0, '--sparsity': 0.005, '--momentsparsity': 0.001, '--npseed': -1, '--torchseed': -1, '--maxiter': 2000, '--recordfile': 'None', '--recordcycle': 200, '--savecycle': -1, '--start_from': -1}
block:  0
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  1.6577139523077333
current stage is: warmup
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.7606, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2651,  2.2673,  2.0973, 20.6929, 10.9892, 18.2429,  0.2458,  1.9830,
         2.0837, 17.2082,  9.9621, 19.5619], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward1>)
iter:     0    time: 15.40
Func: 4.77e+00  |g|: 2.20e+00
stableloss: 3.12e-04   dataloss: 4.77e+00   sparseloss: 1.44e+01 momentloss: 7.27e+00
iter:   200    time: 10.10
Func: 3.82e-02  |g|: 4.41e-02
stableloss: 1.03e-02   dataloss: 3.82e-02   sparseloss: 4.57e+01 momentloss: 7.27e+00
iter:   400    time: 9.80
Func: 3.70e-02  |g|: 9.20e-03
stableloss: 1.06e-02   dataloss: 3.70e-02   sparseloss: 5.10e+01 momentloss: 7.27e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.036676
         Iterations: 563
         Function evaluations: 629
         Gradient evaluations: 620
convolution moment and kernels
[[1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
[[0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
[[ 0.    1.    0.   -0.33 -0.25]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 1.11e-16  2.22e-16 -1.50e+00  2.00e+00 -5.00e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]
[[ 0.    0.    0.    0.    0.  ]
 [ 1.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.  ]
 [-0.33  0.    0.    0.    0.  ]
 [-0.25  0.    0.    0.    0.  ]]
[[ 0.00e+00  0.00e+00  1.11e-16  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  2.22e-16  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -1.50e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  2.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -5.00e-01  0.00e+00  0.00e+00]]
[[0.   0.   1.   0.   0.08]
 [0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [-3.19e-16  1.00e+00 -2.00e+00  1.00e+00 -2.08e-16]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]
[[0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
[[ 0.01 -0.06  0.    0.06 -0.01]
 [-0.06  0.44  0.   -0.44  0.06]
 [ 0.    0.    0.    0.    0.  ]
 [ 0.06 -0.44  0.    0.44 -0.06]
 [-0.01  0.06  0.   -0.06  0.01]]
[[0.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [1.   0.   0.   0.   0.  ]
 [0.   0.   0.   0.   0.  ]
 [0.08 0.   0.   0.   0.  ]]
[[ 0.00e+00  0.00e+00 -3.19e-16  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -2.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  0.00e+00]
 [ 0.00e+00  0.00e+00 -2.08e-16  0.00e+00  0.00e+00]]
SymNet parameters
[[ 7.89e-01  5.09e-01 -9.34e-01 -7.31e-02  8.25e-02 -2.61e-02  2.83e-01 -5.02e-02
   7.62e-03 -5.67e-03 -2.70e-02  1.01e-02]
 [-7.51e-01  2.77e-01 -1.34e-01  2.52e-02 -2.12e-02  7.56e-03 -2.90e+00  1.94e-02
   1.17e-03 -1.05e-03  5.87e-03  2.24e-03]]
SymNet parameters
[-0.16 -0.09]
SymNet parameters
[[-1.98e+00 -2.58e-02 -2.93e-01  2.28e-02 -1.59e-02  5.40e-03 -4.16e-01  3.18e-03
   3.83e-03  3.86e-05  6.30e-03 -9.25e-04  3.70e-03]
 [-1.22e+00 -1.31e+00  6.68e-01 -1.24e-01  1.65e-01 -5.32e-02 -1.98e+00 -9.45e-02
   1.81e-02 -1.02e-02 -3.67e-02  2.18e-02  1.19e-02]]
SymNet parameters
[0.07 0.39]
SymNet parameters
[[-2.03e+00  2.76e-01 -1.53e-01  3.30e-02 -2.78e-02  3.44e-03 -1.71e+00  2.73e-02
  -1.09e-02 -2.07e-03  9.97e-03  1.70e-04  4.84e-03  1.73e-02]
 [-8.36e-01  8.49e-01  1.43e-01 -1.81e-01  2.23e-01 -7.16e-02  1.99e-01 -1.42e-01
   2.44e-02 -1.22e-02 -5.92e-02  2.69e-02  1.48e-02  1.55e-03]]
SymNet parameters
[ 0.11 -1.23]
SymNet parameters
[[-6.25e-01 -3.50e-04 -1.97e-02  4.85e-02 -1.57e-02  4.23e-02 -3.45e-01  1.51e-02
  -1.01e-03  5.07e-04  2.97e-03 -2.21e-05 -2.84e-01 -2.02e-01  1.99e-01]]
SymNet parameters
[0.04]
SymNet parameters
[[ 4.49e-01  7.42e-04 -3.30e-03  2.03e-03  1.65e-03  6.91e-04  5.57e-01 -9.51e-01
   7.68e-01 -2.44e-03 -2.08e-04  3.68e-03]
 [-4.32e-01  2.02e-03  1.97e-03  1.62e-05  2.08e-03 -1.29e-03 -1.70e+00 -2.24e-01
   6.24e-02 -1.91e-03  1.57e-04  2.95e-03]]
SymNet parameters
[-1.78 -0.21]
SymNet parameters
[[ 0.42 -0.36 -0.28 -0.03 -0.02  0.01 -2.82 -0.75 -0.7  -0.36  0.16 -0.1  -0.32]
 [ 0.35 -0.46 -0.49  0.11  0.24 -0.06  2.82 -0.79 -0.84  0.01 -0.51  1.24  0.08]]
SymNet parameters
[0.29 0.25]
SymNet parameters
[[ 2.04e-01 -5.57e-04 -2.87e-03  3.59e-03  7.12e-04  4.08e-04  7.99e-01 -1.38e+00
   3.49e-01 -2.97e-03  2.03e-03  9.22e-04 -1.07e-03  1.21e-03]
 [-9.61e-01  1.55e-03 -3.90e-04  5.99e-04  1.52e-03 -1.33e-03 -1.19e+00 -1.58e-01
   1.32e-01 -1.57e-03 -2.71e-04  3.05e-03  8.26e-04 -2.55e-04]]
SymNet parameters
[-1.04  0.24]
SymNet parameters
[[ 3.51e-01  1.30e-03 -1.21e-03  5.41e-04  1.64e-03  4.82e-04 -1.33e+00 -6.97e-01
   1.98e-01  3.43e-02 -1.94e-05  4.25e-02  9.16e-01  3.10e-04 -9.05e-01]]
SymNet parameters
[-0.57]
finally, finish this stage
iter:   563    time: 9.90
Func: 3.67e-02  |g|: 9.24e-03
stableloss: 1.05e-02   dataloss: 3.67e-02   sparseloss: 5.99e+01 momentloss: 7.27e+00
current expression:
Time out
block:  1
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -1.3696827376670195
current stage is: block-1
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8612, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2659,  2.3206,  2.0851, 21.7292, 11.2940, 18.2461,  0.2588,  2.0045,
         2.0977, 17.1618,  9.6482, 19.3453], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward1>)
iter:     0    time: 18.48
Func: 3.52e-01  |g|: 9.95e-01
stableloss: 1.31e-02   dataloss: 4.55e-02   sparseloss: 5.99e+01 momentloss: 7.27e+00
iter:   200    time: 10.06
Func: 9.27e-02  |g|: 3.33e-02
stableloss: 1.15e-02   dataloss: 2.05e-02   sparseloss: 1.31e+01 momentloss: 6.98e+00
iter:   400    time: 10.50
Func: 8.82e-02  |g|: 5.10e-03
stableloss: 1.15e-02   dataloss: 2.09e-02   sparseloss: 1.21e+01 momentloss: 7.02e+00
iter:   600    time: 10.03
Func: 8.82e-02  |g|: 5.46e-07
stableloss: 1.16e-02   dataloss: 2.09e-02   sparseloss: 1.21e+01 momentloss: 7.00e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.088161
         Iterations: 611
         Function evaluations: 630
         Gradient evaluations: 630
convolution moment and kernels
[[ 1.00e+00  0.00e+00  2.14e-03 -6.91e-02 -4.39e-02]
 [ 0.00e+00  2.94e-04  7.91e-03 -3.64e-03  1.80e-02]
 [ 3.14e-04 -1.08e-03  3.51e-03  6.89e-03 -5.82e-03]
 [-2.31e-02 -6.86e-03  1.37e-03  9.44e-03 -1.84e-02]
 [-5.59e-02 -3.83e-03 -1.45e-04 -8.65e-03  1.74e-03]]
[[ 0.02 -0.07  0.03 -0.04  0.01]
 [-0.07  0.23 -0.07  0.13 -0.02]
 [ 0.05 -0.06  0.57  0.19 -0.09]
 [ 0.   -0.03  0.32 -0.07  0.03]
 [-0.01  0.03 -0.12  0.03 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -1.25e-01 -9.35e-02]
 [ 0.00e+00  0.00e+00  6.64e-03 -3.19e-04  1.37e-02]
 [ 0.00e+00  5.86e-03 -1.86e-02  3.82e-03 -3.09e-02]
 [-9.38e-03 -1.34e-03 -2.22e-03  8.46e-03 -4.95e-03]
 [-8.09e-04 -7.49e-03 -8.33e-03 -1.25e-02 -9.44e-03]]
[[ 0.01 -0.01 -0.    0.02 -0.01]
 [-0.05  0.11 -0.12  0.03  0.01]
 [ 0.11 -0.55 -0.43  1.12 -0.26]
 [-0.01 -0.    0.04 -0.04  0.03]
 [-0.01  0.03 -0.05  0.03 -0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00 -4.85e-05  1.05e-02]
 [ 1.00e+00  0.00e+00  5.17e-04 -4.67e-03 -2.71e-02]
 [ 0.00e+00 -1.37e-03 -1.53e-02 -4.47e-04 -5.61e-03]
 [-1.53e-01 -3.76e-03  4.82e-03  2.76e-03 -1.57e-02]
 [-9.84e-02 -3.63e-03 -1.13e-02 -8.94e-04 -1.31e-03]]
[[ 0.01 -0.04  0.12 -0.03  0.  ]
 [-0.01  0.04 -0.5   0.04  0.  ]
 [ 0.02 -0.1  -0.42 -0.11  0.02]
 [-0.    0.03  1.13  0.06 -0.01]
 [-0.01  0.02 -0.28  0.01 -0.  ]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  8.97e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  3.61e-04 -4.49e-03]
 [ 0.00e+00  0.00e+00  3.48e-03 -2.77e-03 -2.33e-03]
 [ 0.00e+00 -9.80e-04 -4.70e-03  2.13e-03  7.34e-03]
 [ 1.86e-01 -4.50e-03 -2.18e-03  2.53e-03 -6.94e-03]]
[[-1.20e-02  4.74e-02  1.22e-01  3.86e-02 -9.58e-03]
 [ 4.17e-02 -1.52e-01 -5.57e-01 -1.05e-01  2.69e-02]
 [-1.22e-01  1.45e+00 -1.49e+00  1.37e+00 -9.51e-02]
 [ 2.23e-02 -6.17e-02 -7.05e-01 -4.90e-03  3.39e-03]
 [-4.62e-03  1.15e-02  1.82e-01 -2.73e-03  1.21e-05]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  8.17e-04]
 [ 0.00e+00  1.00e+00  0.00e+00 -2.43e-04  2.81e-04]
 [ 0.00e+00  0.00e+00 -1.15e-04  7.30e-04  7.00e-04]
 [ 0.00e+00 -1.73e-04  4.89e-04  8.91e-05 -1.07e-03]
 [ 3.91e-04  6.50e-04  4.73e-04  2.26e-04 -1.81e-03]]
[[ 0.01 -0.05 -0.01  0.06 -0.01]
 [-0.05  0.42  0.04 -0.48  0.06]
 [-0.01  0.05 -0.08  0.05 -0.01]
 [ 0.07 -0.48  0.06  0.4  -0.05]
 [-0.01  0.07 -0.02 -0.04  0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  9.84e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  5.11e-04 -5.08e-03]
 [ 1.00e+00  0.00e+00  3.17e-03 -3.38e-03 -1.91e-03]
 [ 0.00e+00 -9.42e-04 -5.21e-03  2.09e-03  8.06e-03]
 [ 8.67e-03 -5.03e-03 -1.11e-03  3.21e-03 -8.91e-03]]
[[-1.49e-02  6.00e-02 -1.57e-01  4.89e-02 -1.17e-02]
 [ 5.37e-02 -2.02e-01  1.56e+00 -1.45e-01  3.49e-02]
 [-5.40e-02  1.84e-01 -2.64e+00  8.81e-02 -2.13e-02]
 [ 3.18e-02 -1.01e-01  1.39e+00 -3.50e-02  9.20e-03]
 [-6.67e-03  2.00e-02 -9.05e-02  3.73e-03 -1.26e-03]]
SymNet parameters
[[-1.17e-04 -5.83e-04 -9.82e-01  5.21e-06 -6.51e-03  3.12e-04 -9.05e-05 -4.05e-04
   7.08e-05  6.10e-04  2.65e-04 -7.37e-06]
 [ 4.21e-05  6.20e-04  8.69e-04  2.08e-04 -5.42e-04 -6.17e-04 -9.86e-01 -2.91e-04
   1.40e-03  2.63e-04  5.62e-04  8.28e-05]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-9.80e-01 -4.33e-04  6.36e-04 -8.38e-04 -2.48e-04  4.18e-04 -5.60e-04  9.65e-06
   3.78e-04 -6.70e-04  4.24e-05  5.28e-04  8.87e-03]
 [ 4.57e-04 -9.89e-01 -3.64e-05 -1.38e-03  5.21e-04 -3.18e-05 -1.22e-04 -7.15e-04
  -1.53e-04 -1.59e-04 -5.16e-04  6.71e-05 -1.54e-05]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 8.20e-12 -2.00e-11  1.82e-11  5.13e-11  7.41e-12  2.42e-11  2.42e-11  1.13e-11
  -2.88e-11 -5.00e-11  4.96e-11  1.63e-11  3.68e-11  4.45e-11]
 [ 2.26e-11  4.68e-12 -9.43e-12  9.56e-12  7.34e-12 -1.76e-10 -4.37e-12  3.14e-11
   1.31e-11 -3.17e-11  2.39e-10  1.24e-11  6.35e-11 -4.11e-11]]
SymNet parameters
[ 2.98e-11 -7.86e-12]
SymNet parameters
[[ 7.17e-04 -5.65e-04 -4.25e-04  4.84e-02 -4.10e-04  5.34e-02  3.75e-04  1.91e-04
   3.35e-04 -6.09e-04 -9.64e-04  3.83e-04 -9.81e-01 -9.92e-01 -1.33e-11]]
SymNet parameters
[0.]
SymNet parameters
[[ 4.88e-04 -3.11e-04  2.76e-05  4.87e-04  6.50e-05 -7.14e-04 -1.84e-04  4.31e-04
   9.80e-01  3.65e-04  6.36e-03 -4.06e-04]
 [-4.48e-04  1.21e-04 -1.86e-04  4.66e-05 -3.83e-04 -8.94e-04 -9.86e-01 -7.63e-04
   5.48e-04  2.88e-04 -2.77e-04 -6.05e-04]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[ 2.20e-11 -1.27e-11 -1.69e-11  2.17e-12 -2.73e-11 -3.81e-11  7.17e-12 -9.82e-12
  -1.29e-12 -2.12e-11 -1.32e-11  1.89e-11 -1.13e-11]
 [ 4.86e-11  2.48e-11 -1.07e-11  5.80e-12  8.91e-12  2.93e-11  1.55e-11  7.10e-12
  -8.60e-12 -9.24e-12 -1.73e-12 -5.73e-12 -1.27e-11]]
SymNet parameters
[ 1.99e-11 -1.60e-11]
SymNet parameters
[[ 8.65e-04 -3.33e-05 -6.02e-05 -2.96e-05  1.44e-04  4.05e-04 -4.90e-04 -9.85e-01
  -4.55e-04 -1.94e-03  4.79e-04  2.05e-05  1.17e-05  2.07e-12]
 [-9.87e-01 -1.14e-04 -1.45e-04  2.43e-04 -1.92e-04  1.14e-04 -4.30e-04  6.97e-04
  -7.61e-04  2.61e-04 -6.49e-04 -3.03e-04 -4.77e-05  5.74e-11]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-3.59e-04  3.09e-04 -3.61e-04 -4.20e-04 -6.59e-04  1.32e-04  7.29e-04  1.16e-04
  -1.84e-04  4.89e-02 -7.29e-04  5.21e-02  9.89e-01  1.49e-10 -9.89e-01]]
SymNet parameters
[0.]
finally, finish this stage
iter:   611    time: 0.60
Func: 8.82e-02  |g|: 9.31e-09
stableloss: 1.16e-02   dataloss: 2.09e-02   sparseloss: 1.21e+01 momentloss: 7.00e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01*u10*v00, u11*v00, u00, u10*v10, u00*u02, u01*u10, u01*v00, u01, v11, u10**2, u10, u01*u02, v00, u00*v01, u01*v02, v02]
[-9.61e-01 -9.50e-01  5.34e-02  4.84e-02  8.42e-03 -6.30e-03  1.40e-03  1.35e-03
 -1.34e-03  1.22e-03 -1.12e-03 -1.11e-03 -9.64e-04  8.37e-04 -8.28e-04 -8.22e-04
  7.33e-04 -6.95e-04 -6.58e-04 -6.09e-04]
[u00*v01, v00*v10, v20, v02, v00*v11, u00*v02, v01*v10, v00, u00*v00, u00*v10, u20*v10, u00**2, v00*v01, v11, u00, u20*v00, v01**2, u11, v01*v11, v10*v20]
[-9.62e-01 -9.56e-01  5.21e-02  4.89e-02 -6.20e-03 -1.89e-03 -1.48e-03  1.42e-03
 -9.53e-04 -8.78e-04 -8.67e-04  8.44e-04 -8.39e-04 -7.30e-04 -7.01e-04  6.97e-04
  6.78e-04 -6.59e-04 -6.37e-04 -5.87e-04]
block:  2
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -2.2473217950947264
current stage is: block-2
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8636, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2405,  1.7539,  1.6793, 20.6156,  9.9626, 18.4075,  0.2498,  1.6151,
         1.7869, 16.4743,  9.5597, 21.4938], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward1>)
iter:     0    time: 10.48
Func: 2.29e-01  |g|: 1.37e+00
stableloss: 3.28e-02   dataloss: 9.45e-02   sparseloss: 1.21e+01 momentloss: 7.00e+00
iter:   200    time: 17.06
Func: 2.22e-01  |g|: 7.95e-04
stableloss: 3.09e-02   dataloss: 8.61e-02   sparseloss: 1.21e+01 momentloss: 7.27e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.221658
         Iterations: 304
         Function evaluations: 347
         Gradient evaluations: 347
convolution moment and kernels
[[ 1.00e+00  0.00e+00  2.16e-03  9.54e-03 -1.44e-02]
 [ 0.00e+00 -5.06e-04  6.11e-03 -3.82e-03  3.38e-02]
 [ 4.06e-03 -9.01e-03 -1.73e-03  3.20e-03  4.82e-03]
 [-7.99e-03 -2.54e-03 -6.39e-03  6.22e-03 -2.87e-03]
 [-2.67e-02  8.26e-04 -8.48e-04 -6.26e-03  2.56e-03]]
[[ 1.14e-02 -3.34e-02  7.92e-03 -9.79e-03  9.42e-04]
 [-4.89e-02  1.54e-01 -4.76e-02  5.44e-02 -7.90e-03]
 [ 9.07e-03 -8.01e-03  7.60e-01  1.01e-01 -3.15e-02]
 [ 9.25e-03 -4.16e-02  2.21e-01 -1.00e-01  3.20e-02]
 [-1.45e-04 -8.43e-04 -3.25e-02  5.82e-03 -3.31e-03]]
[[ 0.00e+00  1.00e+00  0.00e+00 -1.08e-01 -9.60e-02]
 [ 0.00e+00  0.00e+00  3.36e-03 -5.40e-03  4.22e-03]
 [ 0.00e+00  1.06e-02 -6.85e-02  2.17e-02 -4.20e-02]
 [-5.17e-03  8.17e-03 -3.67e-03  5.24e-03 -1.02e-02]
 [ 2.67e-04 -2.16e-02 -3.38e-02 -1.39e-02 -1.22e-02]]
[[ 0.01 -0.02  0.05 -0.02 -0.01]
 [-0.06  0.15 -0.22  0.11  0.01]
 [ 0.13 -0.59 -0.31  1.02 -0.26]
 [-0.03  0.06 -0.08  0.03  0.03]
 [-0.01  0.02 -0.01  0.02 -0.02]]
[[ 0.    0.    0.    0.   -0.  ]
 [ 1.    0.    0.    0.02 -0.04]
 [ 0.   -0.01 -0.05 -0.   -0.02]
 [-0.12 -0.01  0.03  0.   -0.01]
 [-0.1  -0.   -0.03 -0.   -0.01]]
[[ 1.25e-03 -4.53e-02  1.29e-01 -4.00e-02 -8.94e-04]
 [ 9.43e-03  4.79e-02 -5.04e-01  4.73e-02  6.70e-03]
 [ 2.05e-02 -1.19e-01 -4.03e-01 -9.29e-02  9.48e-03]
 [-3.16e-02  1.16e-01  1.02e+00  7.69e-02 -8.65e-03]
 [-5.20e-03  1.88e-02 -2.64e-01  2.01e-02 -8.57e-03]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  8.01e-03]
 [ 0.00e+00  0.00e+00  0.00e+00 -2.94e-03 -7.22e-03]
 [ 0.00e+00  0.00e+00  9.45e-03  1.61e-03  1.08e-03]
 [ 0.00e+00  2.53e-03 -7.13e-03  1.63e-03  8.75e-03]
 [ 9.90e-03 -9.64e-04  4.51e-04 -1.98e-03 -9.40e-03]]
[[-0.01  0.06 -0.08  0.06 -0.02]
 [ 0.05 -0.2   0.27 -0.21  0.06]
 [-0.13  1.5  -2.69  1.52 -0.14]
 [ 0.02 -0.07  0.07 -0.08  0.03]
 [-0.    0.01 -0.01  0.01 -0.  ]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -6.98e-04]
 [ 0.00e+00  1.00e+00  0.00e+00  4.75e-06  1.62e-03]
 [ 0.00e+00  0.00e+00  4.34e-05 -2.99e-04 -6.28e-06]
 [ 0.00e+00 -9.78e-05  7.02e-04 -7.31e-05 -1.82e-03]
 [-4.42e-05 -4.85e-04 -2.65e-04  7.18e-04  4.84e-04]]
[[ 8.10e-03 -6.14e-02  1.07e-02  4.75e-02 -4.94e-03]
 [-5.87e-02  4.62e-01 -3.34e-02 -4.18e-01  4.87e-02]
 [-4.11e-04 -4.14e-03  1.73e-02 -1.81e-02  5.13e-03]
 [ 5.82e-02 -4.52e-01  4.90e-03  4.46e-01 -5.64e-02]
 [-7.91e-03  5.90e-02 -3.63e-03 -5.43e-02  6.77e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  8.92e-02]
 [ 0.00e+00  0.00e+00  0.00e+00 -2.96e-03 -7.77e-03]
 [ 1.00e+00  0.00e+00  1.18e-01  6.45e-04  5.96e-04]
 [ 0.00e+00  2.62e-03 -7.03e-03  1.50e-03  8.76e-03]
 [ 1.48e-01 -2.39e-03  7.91e-04  2.30e-04 -4.61e-02]]
[[-0.05  0.2  -0.23  0.2  -0.05]
 [ 0.19 -0.6   1.57 -0.59  0.19]
 [-0.17  0.38 -2.02  0.36 -0.16]
 [ 0.16 -0.48  1.36 -0.46  0.16]
 [-0.04  0.15 -0.15  0.15 -0.04]]
SymNet parameters
[[-2.85e-04 -6.51e-04 -9.91e-01  8.56e-04  2.37e-04  7.43e-05  2.20e-04 -2.17e-04
  -5.75e-04 -2.68e-04  4.43e-04 -2.47e-04]
 [ 6.07e-04  7.76e-04 -6.25e-04 -1.76e-04 -4.38e-04 -1.56e-04 -9.89e-01 -1.10e-03
  -9.16e-04  1.07e-04  1.37e-05  1.54e-05]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-9.84e-01  4.92e-04  8.10e-04 -9.87e-04  1.12e-04 -2.00e-05 -6.92e-04  4.37e-04
  -4.06e-04  7.41e-04 -6.47e-04 -5.28e-04  1.02e-02]
 [ 4.43e-04 -9.90e-01  5.55e-04  6.97e-04  5.64e-04 -8.05e-04 -2.75e-04 -1.51e-03
   9.51e-04  1.22e-03 -6.65e-04 -6.14e-04 -4.32e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-1.42e-13  2.22e-11 -2.49e-12  1.23e-12  2.07e-11 -1.99e-11 -2.06e-12 -2.13e-12
  -1.71e-11  2.52e-11 -8.56e-13 -1.24e-11  6.49e-12  1.10e-11]
 [-1.40e-12 -2.23e-11  2.59e-12  1.32e-11 -1.58e-11  5.60e-12 -6.14e-13 -2.21e-12
  -4.62e-12 -1.77e-11 -2.17e-11 -5.76e-12 -3.26e-12  3.27e-11]]
SymNet parameters
[-1.40e-12  5.65e-13]
SymNet parameters
[[ 7.06e-03 -2.67e-04 -6.10e-04  5.12e-02  2.65e-04  5.14e-02 -1.88e-04  8.47e-04
  -8.01e-04 -9.06e-05 -3.12e-04  1.44e-04 -9.83e-01 -9.98e-01 -1.57e-11]]
SymNet parameters
[-8.5e-05]
SymNet parameters
[[ 4.09e-04  2.84e-04  2.58e-04  1.84e-04 -1.18e-04 -2.21e-06  3.17e-04 -1.52e-04
   9.89e-01 -7.16e-04 -4.12e-04  5.28e-04]
 [ 3.17e-04  1.13e-03  4.61e-04  2.32e-04  8.72e-05 -2.70e-04 -9.87e-01 -6.21e-04
  -1.13e-03 -6.37e-05  2.28e-04 -1.19e-03]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-1.51e-11 -2.18e-10  1.95e-10  5.46e-11  6.24e-11 -1.10e-10 -5.80e-11  9.48e-11
   5.58e-12  6.12e-13 -4.06e-11  2.95e-11 -9.82e-11]
 [-1.03e-10  1.95e-11 -1.17e-11  1.21e-11  1.10e-11  6.32e-11  1.90e-11  1.59e-10
   2.25e-11  1.17e-11  9.44e-11 -1.22e-10  1.04e-10]]
SymNet parameters
[-5.62e-12 -3.50e-12]
SymNet parameters
[[ 2.03e-03  3.87e-04  5.36e-04  2.91e-04 -3.19e-04 -1.93e-04 -4.03e-04 -9.86e-01
   3.06e-04 -8.57e-04  5.97e-04 -1.16e-04  8.41e-04  1.09e-10]
 [-9.89e-01  5.48e-04 -7.42e-04 -5.92e-05 -9.62e-05  3.20e-04  1.58e-04  1.03e-04
  -5.88e-04  3.82e-04 -5.28e-04 -1.27e-04 -2.45e-04 -1.57e-10]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-4.92e-04 -2.60e-03 -2.74e-04 -3.27e-04 -2.69e-04 -2.18e-04  4.00e-03  7.47e-04
  -4.26e-04  4.96e-02 -3.20e-04  5.21e-02  9.91e-01  1.50e-10 -9.91e-01]]
SymNet parameters
[0.]
finally, finish this stage
iter:   304    time: 9.49
Func: 2.22e-01  |g|: 1.51e-08
stableloss: 3.09e-02   dataloss: 8.61e-02   sparseloss: 1.21e+01 momentloss: 7.26e+00
current expression:
[u00*u01, u10*v00, u20, u02, u01*u10*v00, u00, u01*u10, u00*v01, u01*v00, u00*v02, u10, u00*u10, u10*v01, u01*u02, u00*v10, u10*v10, v01, u02*v00, v10, u00*u20]
[-9.72e-01 -9.64e-01  5.14e-02  5.12e-02  9.87e-03  8.04e-03  1.56e-03 -1.48e-03
 -1.32e-03  1.20e-03 -1.20e-03  1.14e-03 -1.07e-03 -9.76e-04  9.34e-04 -8.93e-04
  8.46e-04  8.32e-04 -8.01e-04 -7.91e-04]
[v00*v10, u00*v01, v20, v02, v00, u01, u00**2, v01, v01*v10, v10*v20, v10**2, u01*v10, u00, u00*v02, v10, u00*v00*v10, u00*v00, u10*v01, v00*v02, u00*v10]
[-9.67e-01 -9.67e-01  5.21e-02  4.96e-02  4.96e-03 -2.60e-03  1.99e-03  1.46e-03
 -1.18e-03 -1.17e-03 -1.11e-03  1.11e-03 -9.68e-04 -8.41e-04 -8.35e-04 -8.06e-04
 -7.95e-04 -7.26e-04  7.01e-04  6.11e-04]
block:  3
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -1.1603287580677577
current stage is: block-3
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9180, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2469,  1.7454,  1.6048, 22.3123,  9.7237, 14.1747,  0.2542,  1.5705,
         1.7845, 17.6634, 10.1576, 16.9119], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward1>)
iter:     0    time: 10.98
Func: 4.62e-01  |g|: 3.05e+00
stableloss: 3.66e-02   dataloss: 2.58e-01   sparseloss: 1.21e+01 momentloss: 7.27e+00
iter:   200    time: 23.07
Func: 4.37e-01  |g|: 9.32e-04
stableloss: 3.86e-02   dataloss: 2.30e-01   sparseloss: 1.22e+01 momentloss: 7.90e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.437252
         Iterations: 279
         Function evaluations: 354
         Gradient evaluations: 342
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -4.57e-03 -9.16e-02 -1.23e-01]
 [ 0.00e+00 -3.76e-04 -6.92e-03  9.24e-03  4.25e-03]
 [-5.18e-04  5.61e-03  2.02e-02  9.51e-03 -4.74e-02]
 [ 2.21e-02 -3.28e-03 -1.82e-02 -3.49e-03 -6.39e-04]
 [-6.23e-02  3.11e-03  2.49e-02 -5.24e-03  1.09e-03]]
[[ 0.01  0.01 -0.12  0.03  0.  ]
 [-0.08  0.2   0.06  0.14 -0.05]
 [ 0.07 -0.03  0.41  0.27 -0.08]
 [-0.08  0.22 -0.01  0.13 -0.04]
 [ 0.01 -0.01 -0.06  0.01 -0.  ]]
[[ 0.    1.    0.   -0.11 -0.1 ]
 [ 0.    0.   -0.01 -0.03 -0.01]
 [ 0.    0.04 -0.08  0.05 -0.06]
 [ 0.    0.    0.   -0.01  0.  ]
 [ 0.   -0.01 -0.03 -0.01 -0.02]]
[[-5.55e-03  2.22e-02 -3.79e-02  4.33e-02 -2.15e-02]
 [-6.52e-02  1.08e-01 -4.48e-02 -6.04e-02  5.80e-02]
 [ 1.74e-01 -6.34e-01 -3.98e-01  1.15e+00 -2.87e-01]
 [-6.92e-02  1.35e-01 -1.19e-01  1.41e-02  2.89e-02]
 [ 7.83e-04  1.93e-03 -1.05e-02  2.75e-02 -1.67e-02]]
[[ 0.    0.    0.   -0.02  0.01]
 [ 1.    0.    0.02 -0.02 -0.03]
 [ 0.    0.   -0.06  0.01 -0.01]
 [-0.12 -0.02  0.04  0.03 -0.01]
 [-0.1   0.01 -0.04  0.02 -0.01]]
[[ 6.12e-04 -6.57e-02  1.57e-01 -5.13e-02  2.27e-03]
 [ 2.44e-02  5.67e-02 -5.29e-01  6.05e-02 -1.05e-03]
 [-4.23e-02 -2.26e-02 -4.18e-01 -1.50e-01  4.05e-02]
 [ 5.91e-02 -6.73e-02  1.08e+00  1.58e-01 -5.60e-02]
 [-2.58e-02  5.47e-02 -2.59e-01 -2.05e-02  1.02e-02]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  7.47e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  4.71e-03  1.35e-03]
 [ 0.00e+00  0.00e+00  9.37e-03  1.51e-03  6.93e-03]
 [ 0.00e+00 -2.28e-03  2.55e-03  5.34e-04 -4.93e-03]
 [ 1.30e-01  1.00e-03  9.33e-03 -2.62e-03 -4.93e-02]]
[[-0.05  0.19 -0.17  0.2  -0.05]
 [ 0.2  -0.82  0.74 -0.85  0.21]
 [-0.38  2.58 -3.63  2.62 -0.4 ]
 [ 0.21 -0.87  0.82 -0.9   0.22]
 [-0.05  0.22 -0.21  0.23 -0.05]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.10e-03]
 [ 0.00e+00  1.00e+00  0.00e+00 -8.47e-04 -4.02e-03]
 [ 0.00e+00  0.00e+00 -7.64e-04 -1.36e-03 -8.02e-04]
 [ 0.00e+00 -1.73e-04 -4.09e-03  3.52e-04  6.79e-03]
 [-6.29e-02  1.06e-03  7.54e-04 -7.93e-04 -1.07e-03]]
[[ 0.   -0.03 -0.1   0.08 -0.01]
 [-0.04  0.39  0.35 -0.51  0.07]
 [-0.01  0.03 -0.44  0.04 -0.01]
 [ 0.05 -0.42  0.21  0.47 -0.06]
 [-0.    0.04 -0.04 -0.07  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.50e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  4.79e-03  4.74e-03]
 [ 1.00e+00  0.00e+00  1.86e-01  4.80e-04  4.83e-03]
 [ 0.00e+00 -2.42e-03  3.24e-03  3.44e-04 -7.70e-03]
 [ 8.06e-03 -5.28e-04  9.10e-03  1.12e-04 -8.18e-03]]
[[-0.    0.01 -0.08  0.01 -0.  ]
 [ 0.01  0.17  0.94  0.18  0.01]
 [ 0.12 -0.9  -0.89 -0.9   0.12]
 [ 0.03  0.08  1.08  0.08  0.03]
 [-0.01  0.05 -0.14  0.04 -0.01]]
SymNet parameters
[[-2.72e-05 -1.63e-04 -9.85e-01  3.96e-04  7.23e-03  1.91e-04  2.22e-03 -3.37e-03
  -2.95e-03  4.22e-04 -2.03e-04 -2.80e-05]
 [-2.23e-05 -5.10e-04  1.50e-04  3.33e-04 -8.98e-04 -4.46e-04 -9.90e-01  8.95e-03
   1.08e-04  1.00e-03  1.90e-04  2.24e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-9.81e-01  7.60e-03 -6.28e-04  6.67e-05  4.27e-04  4.59e-04 -7.17e-04  1.38e-03
  -1.20e-04  3.68e-05  1.03e-03  1.67e-04  1.01e-02]
 [ 1.31e-04 -9.92e-01  9.22e-06  1.20e-03  2.61e-03  9.66e-04 -3.35e-05  4.36e-05
  -4.66e-04  3.28e-04  2.19e-04 -1.19e-04 -2.83e-04]]
SymNet parameters
[-0.    0.01]
SymNet parameters
[[ 8.86e-13 -5.46e-11  9.76e-12  1.87e-11 -8.63e-11  7.55e-11  7.69e-12  9.60e-12
   6.35e-11 -9.65e-11  4.14e-12  4.38e-11 -2.37e-11 -4.67e-11]
 [ 5.14e-12  9.13e-11 -9.18e-12 -3.82e-11  6.65e-11 -2.15e-11  2.53e-12  8.30e-12
   2.09e-11  7.86e-11  8.13e-11  2.53e-11  4.68e-12 -9.84e-11]]
SymNet parameters
[ 5.29e-12 -2.57e-12]
SymNet parameters
[[ 9.97e-04 -6.79e-03  1.36e-04  5.14e-02 -4.25e-03  5.09e-02 -7.86e-04 -9.32e-04
   2.60e-03 -3.64e-04  2.71e-04 -9.06e-05 -9.91e-01 -1.00e+00  4.30e-11]]
SymNet parameters
[0.]
SymNet parameters
[[-5.40e-04 -3.67e-03 -1.31e-03  3.16e-04 -3.99e-05 -8.16e-04  7.33e-04  5.34e-04
   9.82e-01  1.01e-04 -1.15e-02  5.46e-04]
 [-5.84e-04  1.29e-03  5.48e-04 -3.94e-05  5.11e-05 -4.04e-04 -9.90e-01  7.89e-03
  -3.66e-04  1.46e-03 -6.21e-04 -6.74e-04]]
SymNet parameters
[-9.94e-04  4.71e-06]
SymNet parameters
[[ 1.02e-10 -9.08e-11 -5.30e-11 -1.74e-10  4.19e-10  8.97e-10 -2.13e-10  1.41e-10
  -6.21e-11 -4.10e-10  3.85e-10 -2.11e-10 -7.09e-10]
 [ 7.72e-11  1.24e-09 -2.72e-10 -1.35e-10 -2.94e-10 -3.74e-11 -1.19e-09  2.61e-10
   3.41e-10 -1.19e-09  9.21e-10  7.58e-10 -6.67e-10]]
SymNet parameters
[2.10e-11 1.03e-11]
SymNet parameters
[[ 3.02e-04  7.53e-04  7.06e-04  5.01e-04  3.54e-04 -4.90e-04  5.15e-04 -9.91e-01
  -4.08e-04  9.96e-04  2.08e-03  5.95e-04 -1.15e-03 -1.38e-10]
 [-9.84e-01  7.78e-03 -5.11e-04  1.06e-03 -1.57e-04  9.05e-05 -5.57e-04  1.63e-04
   9.41e-04 -6.80e-05  2.33e-04  2.39e-04  2.04e-03  1.67e-10]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-3.31e-04  1.51e-05 -1.66e-03 -1.54e-04 -1.69e-04  1.29e-04  6.31e-03 -4.50e-03
  -1.18e-05  5.33e-02 -5.13e-03  5.06e-02  9.99e-01  7.23e-10 -9.97e-01]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   279    time: 12.98
Func: 4.37e-01  |g|: 1.13e-07
stableloss: 3.86e-02   dataloss: 2.30e-01   sparseloss: 1.22e+01 momentloss: 7.90e+00
current expression:
[u00*u01, u10*v00, u02, u20, u01*u10*v00, u10*v01, u01, u01**2, u11*v00, u00, u11, v00*v01, v00*v10, v10, u00*u11, v00**2, v00, u01*v01, u00*u02, u01*u10]
[-0.98 -0.97  0.05  0.05  0.01  0.01 -0.01  0.01  0.01  0.01 -0.   -0.   -0.    0.
  0.    0.   -0.    0.    0.   -0.  ]
[u00*v01, v00*v10, v02, v20, v00*v11, v01*v10, u01*v01, v00, v01, v11, u01*v00, u00*v11, v00*v01*v10, u10, v02*v10, u10*v00, u01*v10, u00*v00*v10, v00*v01, u02*v01]
[-0.97 -0.97  0.05  0.05  0.01  0.01  0.01  0.01 -0.01 -0.01  0.    0.   -0.   -0.
  0.    0.    0.    0.   -0.    0.  ]
block:  4
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  1.9669721457468916
current stage is: block-4
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.7824, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2433,  1.6827,  1.6284, 22.2039, 10.4079, 15.8870,  0.2467,  1.6279,
         1.6918, 18.7893, 10.0901, 18.5335], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward1>)
iter:     0    time: 11.73
Func: 6.60e-01  |g|: 6.40e+00
stableloss: 3.17e-02   dataloss: 3.84e-01   sparseloss: 1.22e+01 momentloss: 7.90e+00
iter:   200    time: 28.89
Func: 6.12e-01  |g|: 2.91e-04
stableloss: 3.40e-02   dataloss: 3.38e-01   sparseloss: 1.22e+01 momentloss: 7.74e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 0.612054
         Iterations: 266
         Function evaluations: 309
         Gradient evaluations: 309
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -3.25e-03 -5.99e-02 -9.52e-02]
 [ 0.00e+00  2.62e-04 -5.47e-02  6.05e-03 -7.70e-02]
 [ 5.16e-04 -2.86e-03  4.27e-02  1.34e-02 -1.49e-02]
 [ 3.48e-02 -2.90e-03  4.43e-02  2.99e-03  9.96e-03]
 [-6.42e-02 -3.51e-02  1.98e-03 -3.95e-02  4.92e-03]]
[[ 1.51e-02 -3.61e-02 -4.23e-02  2.56e-03 -2.09e-02]
 [-6.53e-02  1.72e-01  9.86e-02 -3.87e-05  8.73e-02]
 [ 1.28e-01 -2.11e-01  6.88e-01  1.78e-01 -1.69e-01]
 [-1.75e-01  4.44e-01 -3.02e-01  2.77e-01 -2.13e-02]
 [ 3.22e-02 -5.21e-02 -4.42e-03 -2.13e-02 -1.34e-03]]
[[ 0.00e+00  1.00e+00  0.00e+00 -1.08e-01 -1.03e-01]
 [ 0.00e+00  0.00e+00 -5.99e-03 -7.61e-03 -1.23e-02]
 [ 0.00e+00  5.62e-02 -3.10e-02  9.21e-02 -4.17e-02]
 [ 5.09e-03 -3.15e-04  1.51e-02 -1.16e-02  6.76e-03]
 [ 5.96e-03 -6.00e-03  6.73e-04  9.21e-03 -6.15e-03]]
[[-1.09e-02  3.56e-02 -2.71e-02  8.26e-03 -2.47e-03]
 [-4.55e-02  4.46e-02 -5.26e-02  1.71e-02  1.76e-02]
 [ 1.68e-01 -5.80e-01 -3.83e-01  1.08e+00 -2.53e-01]
 [-7.87e-02  1.26e-01 -1.47e-01  7.35e-02 -2.78e-03]
 [ 1.69e-03  1.18e-02 -9.34e-03  4.51e-03 -1.08e-04]]
[[ 0.00e+00  0.00e+00  0.00e+00 -9.00e-04 -2.16e-03]
 [ 1.00e+00  0.00e+00  3.04e-02 -8.40e-04 -9.10e-03]
 [ 0.00e+00 -1.39e-02 -2.09e-02 -4.06e-03  1.50e-02]
 [-1.23e-01 -1.02e-02  3.21e-02  3.10e-02 -1.15e-03]
 [-1.05e-01 -1.77e-02 -4.60e-02  2.01e-03 -2.13e-03]]
[[ 0.01 -0.07  0.16 -0.06 -0.  ]
 [ 0.01  0.08 -0.59  0.1   0.02]
 [-0.05 -0.02 -0.39 -0.16 -0.02]
 [ 0.04  0.01  0.99  0.18 -0.02]
 [-0.01  0.   -0.19 -0.06  0.01]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  7.12e-04]
 [ 0.00e+00  0.00e+00  0.00e+00 -3.41e-03  6.94e-03]
 [ 0.00e+00  0.00e+00  8.48e-02 -6.13e-03  3.07e-03]
 [ 0.00e+00 -1.68e-03  2.06e-03  4.56e-03 -8.36e-03]
 [ 6.61e-02  3.07e-03  4.86e-03  6.55e-03 -2.28e-03]]
[[ 5.70e-04 -1.13e-02  8.75e-02 -1.51e-02  4.41e-03]
 [ 4.86e-03  1.08e-01 -5.02e-01  1.45e-01 -2.03e-02]
 [-1.15e-01  1.21e+00 -1.77e+00  1.13e+00 -6.30e-02]
 [ 3.83e-02 -1.69e-02 -3.36e-01  5.13e-02 -1.13e-03]
 [-1.18e-02  3.58e-02  2.52e-02  1.95e-02 -2.57e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.54e-03]
 [ 0.00e+00  1.00e+00  0.00e+00 -5.67e-05 -6.58e-03]
 [ 0.00e+00  0.00e+00 -9.57e-04  1.41e-03 -1.11e-03]
 [ 0.00e+00 -3.21e-04 -2.19e-03  1.19e-04  6.36e-03]
 [-4.21e-04 -8.15e-04  6.04e-05 -1.11e-03  1.92e-03]]
[[ 0.01 -0.05 -0.01  0.06 -0.01]
 [-0.06  0.44  0.02 -0.46  0.06]
 [ 0.02 -0.07  0.09 -0.06  0.01]
 [ 0.03 -0.36 -0.12  0.52 -0.07]
 [-0.    0.03  0.04 -0.08  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.82e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -2.75e-03  8.65e-03]
 [ 1.00e+00  0.00e+00  7.92e-03 -5.72e-03  4.82e-03]
 [ 0.00e+00 -8.55e-04  2.20e-03  3.60e-03 -1.36e-02]
 [ 6.63e-03  1.91e-03  9.13e-03  5.87e-03 -4.74e-02]]
[[-0.04  0.17 -0.34  0.17 -0.04]
 [ 0.19 -0.76  2.43 -0.72  0.17]
 [-0.14  0.55 -3.23  0.46 -0.09]
 [ 0.24 -0.93  2.67 -0.87  0.2 ]
 [-0.06  0.24 -0.43  0.23 -0.05]]
SymNet parameters
[[ 2.49e-04 -7.34e-04 -9.83e-01  2.55e-04 -5.55e-03  7.45e-04  1.88e-04 -4.13e-03
   3.77e-03  1.84e-04  5.01e-05 -3.80e-04]
 [-1.15e-05 -8.26e-04  5.33e-04 -2.45e-04 -5.26e-04  1.26e-04 -9.96e-01  9.25e-05
   6.87e-04  5.72e-04 -2.54e-04  6.91e-04]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-9.87e-01 -1.74e-05 -8.80e-04 -7.73e-04 -1.31e-04  1.33e-03 -6.18e-04 -3.29e-04
  -6.00e-04  2.83e-04  4.13e-04 -8.35e-04  8.65e-03]
 [ 3.23e-03 -9.88e-01  6.84e-05  3.79e-04  9.28e-04 -1.72e-03  1.83e-04 -2.63e-03
  -8.28e-04 -4.67e-04  7.43e-04 -8.09e-05 -2.33e-03]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-3.35e-13  2.06e-11 -2.26e-12  6.23e-13  2.46e-11 -2.23e-11 -2.12e-12 -2.83e-12
  -1.77e-11  2.17e-11 -7.12e-13 -9.32e-12  5.77e-12  4.40e-12]
 [-1.38e-12 -2.11e-11  2.50e-12  3.95e-12 -1.73e-11  9.07e-12 -8.13e-13 -2.14e-12
  -4.73e-12 -1.37e-11 -2.54e-11 -9.01e-12 -3.57e-12  3.02e-11]]
SymNet parameters
[-1.40e-12  5.55e-13]
SymNet parameters
[[ 6.75e-03 -2.57e-03  1.73e-04  5.06e-02 -1.51e-04  4.94e-02  3.79e-04  1.13e-03
   2.06e-03 -4.44e-05  6.04e-04  2.34e-04 -9.87e-01 -1.00e+00 -7.27e-12]]
SymNet parameters
[0.]
SymNet parameters
[[-9.79e-04 -1.06e-03  3.51e-04 -4.00e-04  2.53e-04 -1.17e-04  6.64e-04 -1.75e-04
   9.85e-01 -9.32e-04  5.03e-03 -2.05e-03]
 [-3.17e-04  4.55e-04  1.61e-03  3.90e-04 -2.80e-04 -2.39e-05 -9.91e-01  2.89e-04
   1.98e-03  9.88e-04  2.18e-04 -5.60e-04]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-8.14e-11  1.80e-10  8.02e-10 -3.52e-10  3.30e-11 -7.88e-10  1.16e-10  9.71e-10
  -1.36e-09 -6.56e-10  7.83e-10  1.34e-09  1.26e-09]
 [-4.91e-10  6.20e-10  3.95e-10 -4.78e-10  1.02e-09  4.23e-10  2.39e-10 -4.53e-10
  -8.35e-10 -2.85e-10  1.23e-09  2.69e-10  6.48e-10]]
SymNet parameters
[-6.38e-12 -1.31e-11]
SymNet parameters
[[-6.82e-04 -1.11e-05 -2.70e-04 -2.61e-04  1.80e-03 -2.32e-04  1.18e-03 -9.87e-01
  -2.20e-04 -1.49e-03  8.60e-04 -6.44e-04  1.00e-03  5.24e-10]
 [-9.91e-01  2.04e-04  3.52e-04  1.30e-03 -4.34e-05 -1.27e-04  1.71e-04  6.77e-04
   3.97e-04 -1.26e-05  4.84e-05 -7.14e-04  1.05e-03 -7.88e-10]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-2.18e-04  4.74e-04 -6.19e-05 -1.38e-04  5.90e-04 -2.51e-04  8.19e-03  3.70e-04
  -4.08e-04  5.20e-02 -1.20e-03  4.87e-02  9.95e-01  6.56e-10 -9.95e-01]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   266    time: 12.03
Func: 6.12e-01  |g|: 8.24e-08
stableloss: 3.40e-02   dataloss: 3.38e-01   sparseloss: 1.22e+01 momentloss: 7.74e+00
current expression:
[u00*u01, u10*v00, u02, u20, u01*u10*v00, u00, u11*v00, v00*v01, v00*v10, u01, u00**2, u00*v01, u00*u10*v00, v10, u00*u20, u01*u10, u01*v00, u01*u20, v01, u00*u11]
[-9.76e-01 -9.67e-01  5.06e-02  4.94e-02  8.38e-03  7.74e-03 -5.46e-03 -4.06e-03
  3.71e-03 -3.55e-03  3.19e-03 -2.60e-03 -2.28e-03  2.06e-03 -1.70e-03 -1.67e-03
 -1.34e-03  1.32e-03  1.13e-03  9.18e-04]
[u00*v01, v00*v10, v02, v20, v00, v00*v11, u00*v00, v00*v20, v10**2, u00*u11, u10*v10, u00*v02, u02*v01, v11, u01*v00, v00*v01*v10, v02*v10, u00*v00*v10, v00*v02, u00*v11]
[-9.73e-01 -9.72e-01  5.20e-02  4.87e-02  9.17e-03 -4.96e-03  2.13e-03  2.02e-03
  1.94e-03  1.77e-03  1.58e-03 -1.47e-03  1.28e-03 -1.20e-03  1.04e-03 -1.01e-03
  9.67e-04 -9.65e-04  9.20e-04  8.46e-04]
block:  5
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -0.3134194212949767
current stage is: block-5
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9647, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2501,  1.8798,  1.6237, 23.0470, 10.6720, 17.8912,  0.2524,  1.6513,
         1.8940, 17.5397, 10.1802, 23.3844], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward1>)
iter:     0    time: 12.53
Func: 1.15e+00  |g|: 1.33e+01
stableloss: 6.55e-02   dataloss: 8.11e-01   sparseloss: 1.21e+01 momentloss: 7.74e+00
iter:   200    time: 34.97
Func: 1.05e+00  |g|: 2.43e-03
stableloss: 6.17e-02   dataloss: 7.00e-01   sparseloss: 1.22e+01 momentloss: 8.35e+00
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 1.045570
         Iterations: 274
         Function evaluations: 368
         Gradient evaluations: 360
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -5.19e-03  5.09e-02 -1.02e-01]
 [ 0.00e+00  2.62e-03  7.83e-03 -7.40e-03  7.12e-03]
 [ 4.64e-04 -2.08e-02  3.17e-02  7.23e-03 -5.94e-02]
 [-1.17e-02  6.76e-03 -3.22e-03 -7.32e-02  1.87e-02]
 [-6.93e-02 -4.01e-02 -5.17e-02 -1.57e-02 -3.38e-02]]
[[-0.05  0.13 -0.16  0.03 -0.02]
 [ 0.06 -0.05  0.08  0.13  0.04]
 [-0.11  0.16  0.63  0.03 -0.14]
 [-0.04  0.23 -0.1   0.12  0.08]
 [ 0.01 -0.02 -0.05  0.03 -0.04]]
[[ 0.00e+00  1.00e+00  0.00e+00 -1.22e-01 -9.84e-02]
 [ 0.00e+00  0.00e+00  1.78e-02  2.91e-03  2.94e-02]
 [ 0.00e+00  4.34e-02 -2.40e-02  8.53e-02 -3.07e-02]
 [-1.05e-02  1.71e-02 -4.32e-03 -4.91e-03  2.70e-03]
 [ 3.42e-03 -3.66e-04  2.56e-03  1.87e-02 -3.12e-03]]
[[-0.01  0.03 -0.01 -0.01  0.01]
 [-0.05  0.08 -0.15  0.12 -0.03]
 [ 0.14 -0.55 -0.41  1.08 -0.23]
 [-0.03  0.03 -0.01 -0.01  0.01]
 [-0.01  0.01 -0.01  0.    0.  ]]
[[ 0.    0.    0.   -0.    0.01]
 [ 1.    0.    0.03 -0.02 -0.01]
 [ 0.   -0.   -0.09  0.02 -0.03]
 [-0.1   0.01  0.05 -0.01 -0.  ]
 [-0.1  -0.02 -0.08 -0.   -0.02]]
[[-0.01 -0.03  0.15 -0.06 -0.01]
 [ 0.03  0.04 -0.57  0.07  0.05]
 [-0.02 -0.06 -0.36 -0.08 -0.07]
 [ 0.03 -0.03  1.11 -0.01  0.06]
 [-0.02  0.03 -0.25  0.03 -0.02]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  8.21e-03]
 [ 0.00e+00  0.00e+00  0.00e+00  1.40e-03 -4.93e-03]
 [ 0.00e+00  0.00e+00  3.51e-01 -2.63e-03  2.02e-02]
 [ 0.00e+00  9.60e-03  7.80e-03 -9.59e-03  3.28e-03]
 [ 1.25e-01 -8.95e-04  8.54e-03 -4.43e-04 -3.53e-03]]
[[-8.03e-03  4.76e-03  1.43e-01 -1.22e-02 -2.40e-03]
 [ 1.81e-02  3.77e-01 -1.32e+00  4.19e-01  3.65e-03]
 [-8.05e-02  4.94e-01 -6.52e-02  4.79e-01 -7.57e-02]
 [-5.86e-03  4.42e-01 -1.36e+00  4.17e-01  3.94e-03]
 [ 1.13e-03 -1.75e-02  1.48e-01 -1.98e-03 -4.66e-03]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -9.74e-04]
 [ 0.00e+00  1.00e+00  0.00e+00 -8.48e-04 -6.38e-03]
 [ 0.00e+00  0.00e+00 -1.47e-03  1.13e-03  3.01e-03]
 [ 0.00e+00  9.96e-05  1.69e-03 -2.62e-04  5.35e-03]
 [-5.38e-03  1.69e-03  3.97e-03 -1.83e-03 -1.12e-03]]
[[ 0.   -0.04 -0.04  0.08 -0.01]
 [-0.04  0.36  0.17 -0.55  0.08]
 [-0.01  0.08 -0.19  0.12 -0.03]
 [ 0.05 -0.45  0.06  0.41 -0.05]
 [-0.    0.05 -0.01 -0.05  0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.01e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  1.11e-03 -6.68e-03]
 [ 1.00e+00  0.00e+00  9.51e-03 -6.79e-04  6.87e-02]
 [ 0.00e+00  7.80e-02  9.21e-03 -9.81e-03  4.40e-03]
 [ 6.97e-03  1.73e-03  1.29e-01 -4.35e-03 -3.55e-03]]
[[-0.03  0.24 -0.46  0.19 -0.02]
 [ 0.16 -1.16  3.22 -1.07  0.15]
 [-0.14  1.33 -4.88  1.4  -0.17]
 [ 0.12 -0.99  3.16 -1.15  0.16]
 [-0.01  0.17 -0.45  0.24 -0.03]]
SymNet parameters
[[ 3.68e-04  7.62e-04 -9.93e-01 -5.97e-04 -9.00e-04 -4.01e-04 -1.09e-04 -3.70e-04
   2.82e-03 -1.65e-04  2.40e-05  8.92e-05]
 [-4.55e-04 -2.30e-04 -8.10e-04 -1.82e-05 -5.39e-04  2.36e-04 -9.88e-01 -2.83e-03
   5.32e-03  5.12e-04 -9.21e-04  6.45e-04]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-9.82e-01 -1.60e-03 -1.56e-05 -3.69e-04 -8.56e-05  4.22e-04  2.81e-03 -7.85e-04
   1.34e-03  5.27e-05  2.80e-04 -2.44e-04  8.54e-03]
 [-4.80e-04 -9.90e-01 -2.32e-04  2.93e-05  3.17e-03  8.74e-04  3.05e-04 -1.09e-03
  -1.16e-03 -5.08e-05 -7.83e-04 -9.38e-05  1.36e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-3.32e-10  2.06e-08 -2.21e-09  6.96e-10  2.44e-08 -2.19e-08 -2.10e-09 -2.74e-09
  -1.75e-08  2.15e-08 -7.07e-10 -9.12e-09  5.72e-09  4.22e-09]
 [-1.36e-09 -2.08e-08  2.47e-09  3.75e-09 -1.72e-08  8.95e-09 -8.03e-10 -2.12e-09
  -4.59e-09 -1.36e-08 -2.50e-08 -8.89e-09 -3.59e-09  3.00e-08]]
SymNet parameters
[-1.38e-09  5.46e-10]
SymNet parameters
[[ 5.54e-03 -7.75e-04 -3.37e-04  5.11e-02  4.33e-03  5.34e-02  1.78e-03 -8.74e-04
  -1.20e-04 -1.54e-04  2.83e-05  2.47e-04 -9.91e-01 -9.98e-01 -8.03e-09]]
SymNet parameters
[-0.]
SymNet parameters
[[-4.68e-04  4.91e-04  4.34e-03 -8.77e-04  1.10e-03  4.24e-04  1.67e-03 -8.72e-04
   9.87e-01 -6.25e-04 -1.79e-03  4.37e-04]
 [ 5.36e-04 -1.32e-04 -6.49e-04  2.13e-04 -5.18e-04 -2.25e-04 -9.93e-01 -5.35e-04
   3.92e-03  6.18e-04 -2.68e-04 -5.23e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 2.75e-07 -5.75e-07  2.92e-07  1.09e-06 -2.14e-07 -7.68e-07  1.01e-06 -9.45e-07
   3.14e-07  9.36e-08 -3.78e-07 -3.82e-07 -7.03e-07]
 [-6.55e-07 -7.24e-08  3.32e-07  2.73e-07  1.20e-06  1.24e-07 -6.21e-07 -1.46e-07
  -6.85e-07 -7.38e-07  4.83e-07  1.53e-06 -6.71e-07]]
SymNet parameters
[-4.61e-08 -2.46e-08]
SymNet parameters
[[ 3.22e-04  9.01e-04 -1.98e-03 -8.54e-05 -9.99e-04 -1.24e-04  4.56e-04 -9.84e-01
   1.59e-03  6.56e-05  5.48e-03 -2.13e-04 -1.72e-03 -6.73e-08]
 [-9.84e-01 -2.15e-03  5.03e-03  8.99e-04 -9.57e-05  4.45e-04  8.17e-04 -6.28e-04
  -1.04e-03 -5.33e-05  1.15e-05  3.74e-05  1.81e-03  7.66e-08]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[ 3.18e-04 -1.17e-03  3.73e-03 -1.33e-04  1.30e-03 -2.04e-04  6.75e-03 -5.84e-04
   5.08e-04  5.14e-02  2.24e-03  5.25e-02  9.96e-01 -1.05e-08 -9.97e-01]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   274    time: 22.31
Func: 1.05e+00  |g|: 4.21e-04
stableloss: 6.16e-02   dataloss: 6.99e-01   sparseloss: 1.22e+01 momentloss: 8.36e+00
current expression:
[u10*v00, u00*u01, u20, u02, u01*u10*v00, u00, u10*v10, u11, u01*v00, u00*u11, u10*v01, v00*v10, v00, u01**2, u01, u01*v10, u00*v10, u00*v01, u10*v11, u11*v00]
[-9.73e-01 -9.70e-01  5.34e-02  5.11e-02  8.28e-03  6.51e-03  5.23e-03  4.33e-03
  3.52e-03  3.10e-03 -2.79e-03  2.76e-03  2.73e-03 -1.58e-03 -1.53e-03  1.32e-03
 -1.14e-03 -1.07e-03 -9.06e-04 -8.90e-04]
[v00*v10, u00*v01, v20, v02, v00, u00*v11, u10*v01, u10*v00, v10**2, u10, v11, u01*v01, u00*v10, u00*u10, v00*v11, v00*v01*v10, v00*v01, u00*v00*v10, v00**2, v01*v10]
[-0.98 -0.97  0.05  0.05  0.01  0.01  0.   -0.    0.    0.    0.   -0.    0.   -0.
  0.   -0.    0.    0.   -0.   -0.  ]
block:  6
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -0.2090369472382907
current stage is: block-6
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.9042, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2377,  1.5840,  1.5870, 16.0141,  9.3091, 21.1653,  0.2648,  1.6900,
         1.8208, 15.0298, 10.5526, 27.8511], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward1>)
iter:     0    time: 12.65
Func: 1.58e+00  |g|: 1.26e+01
stableloss: 6.10e-02   dataloss: 1.17e+00   sparseloss: 1.22e+01 momentloss: 8.36e+00
iter:   200    time: 40.34
Func: 1.46e+00  |g|: 1.01e+00
stableloss: 6.26e-02   dataloss: 1.03e+00   sparseloss: 1.22e+01 momentloss: 1.14e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 1.456940
         Iterations: 372
         Function evaluations: 469
         Gradient evaluations: 459
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -2.39e-03  1.47e-02 -8.56e-02]
 [ 0.00e+00  5.21e-03 -2.40e-02  1.99e-02 -1.14e-01]
 [-2.31e-03  3.34e-03  9.96e-02  1.56e-02  5.37e-03]
 [ 2.41e-02 -9.95e-03  7.66e-03 -5.77e-03 -6.63e-02]
 [-4.34e-02  1.89e-04  2.72e-02  2.16e-03  1.24e-02]]
[[ 0.03 -0.12  0.13 -0.13  0.04]
 [-0.03  0.2  -0.12  0.2  -0.04]
 [-0.01 -0.03  0.82 -0.01 -0.02]
 [-0.07  0.23 -0.17  0.19 -0.04]
 [-0.01  0.08 -0.16  0.08 -0.02]]
[[ 0.    1.    0.   -0.1  -0.1 ]
 [ 0.    0.    0.01  0.02 -0.  ]
 [ 0.    0.05 -0.03  0.08 -0.04]
 [-0.01  0.    0.   -0.02 -0.01]
 [-0.   -0.01 -0.01  0.02 -0.01]]
[[-0.01  0.03  0.01 -0.03  0.01]
 [-0.02  0.03 -0.12  0.14 -0.03]
 [ 0.11 -0.51 -0.42  1.02 -0.23]
 [-0.03  0.03  0.02 -0.02  0.03]
 [-0.01  0.05 -0.08  0.05 -0.01]]
[[ 0.    0.    0.   -0.01 -0.01]
 [ 1.    0.    0.05  0.02  0.02]
 [ 0.    0.02 -0.04  0.01 -0.01]
 [-0.11  0.03  0.04  0.02  0.01]
 [-0.1   0.03 -0.06  0.02 -0.02]]
[[-0.01 -0.02  0.1  -0.02 -0.01]
 [ 0.04  0.06 -0.54  0.06  0.01]
 [-0.07 -0.03 -0.52  0.03 -0.04]
 [ 0.06  0.01  1.15 -0.05  0.03]
 [-0.02 -0.   -0.23  0.01 -0.  ]]
[[ 0.    0.    1.    0.    0.  ]
 [ 0.    0.    0.    0.01  0.  ]
 [ 0.    0.    0.13  0.01  0.22]
 [ 0.    0.    0.   -0.    0.05]
 [ 0.14  0.    0.01  0.01  0.01]]
[[-0.04  0.14 -0.06  0.13 -0.03]
 [ 0.31 -1.07  0.92 -1.01  0.28]
 [-0.57  2.97 -3.93  2.93 -0.54]
 [ 0.21 -0.67  0.36 -0.66  0.19]
 [ 0.01 -0.05  0.23 -0.06  0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  9.69e-03]
 [ 0.00e+00  1.00e+00  0.00e+00  5.32e-01  2.66e-02]
 [ 0.00e+00  0.00e+00  1.20e-04  7.39e-03 -5.11e-03]
 [ 0.00e+00  1.02e+00 -1.05e-03 -3.54e-03 -3.71e-01]
 [ 2.53e-01 -1.14e+00  6.38e-03  8.26e-03 -8.37e-03]]
[[ 0.02  0.39  1.31 -1.81  0.34]
 [ 0.24 -2.24 -3.12  5.06 -0.96]
 [-0.61  4.74  1.26 -4.41  0.55]
 [ 0.6  -4.15  1.54  0.76  0.24]
 [-0.24  1.22 -0.94  0.36 -0.16]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.51e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  1.43e-02  7.82e-02]
 [ 1.00e+00  0.00e+00  2.94e-01  1.31e-02  3.96e-03]
 [ 0.00e+00  4.85e-03  4.87e-03 -2.31e-03  8.06e-05]
 [ 8.32e-03  3.05e-03  2.45e-01  8.15e-03  7.14e-02]]
[[ 0.05 -0.01 -0.15 -0.03  0.06]
 [-0.27  0.53  0.76  0.58 -0.3 ]
 [ 0.5  -1.3  -0.87 -1.3   0.51]
 [-0.18  0.13  1.41  0.12 -0.18]
 [ 0.04  0.04 -0.24  0.04  0.05]]
SymNet parameters
[[-6.34e-05  6.36e-04 -9.88e-01  7.18e-04  2.11e-03  1.36e-03  8.23e-04  1.15e-03
  -6.25e-05  6.22e-05  2.35e-03  1.32e-03]
 [-2.74e-04 -1.56e-03  5.20e-04  1.82e-04 -1.92e-03 -4.73e-04 -9.92e-01 -3.01e-04
   7.15e-04  4.38e-04 -1.15e-03 -2.65e-04]]
SymNet parameters
[ 0. -0.]
SymNet parameters
[[-9.84e-01  3.27e-03 -9.86e-04 -7.68e-04  2.70e-04  2.43e-04  6.96e-04  3.73e-04
   1.88e-03  3.54e-04 -1.10e-03 -2.84e-05  8.68e-03]
 [-1.28e-04 -9.93e-01 -5.22e-04  7.67e-04  3.54e-03  1.03e-03  3.92e-04  7.85e-04
   2.05e-03  3.36e-04 -9.24e-04  1.26e-04 -3.21e-04]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-3.24e-06  5.14e-06  3.02e-05 -1.74e-06 -1.04e-06  4.70e-06  1.41e-05 -1.48e-05
   1.01e-05 -3.58e-07  8.61e-07  9.17e-07  3.00e-06  1.41e-06]
 [ 1.19e-05  6.55e-06  7.16e-06  5.12e-06  8.54e-06  1.59e-05  9.88e-06 -3.09e-05
   1.01e-05  5.93e-06 -3.27e-06 -9.21e-06  5.83e-06  1.26e-06]]
SymNet parameters
[-2.42e-05 -4.78e-06]
SymNet parameters
[[ 4.26e-03  9.30e-04 -1.94e-03  5.17e-02 -7.29e-05  5.31e-02  6.19e-04  1.78e-03
  -7.20e-04 -2.34e-05  4.35e-05 -6.32e-04 -9.90e-01 -1.00e+00 -3.47e-06]]
SymNet parameters
[-0.]
SymNet parameters
[[-9.23e-05 -2.97e-03 -2.13e-05 -9.19e-06 -5.74e-03 -1.33e-03 -5.39e-04  6.78e-05
   9.88e-01 -1.13e-03 -6.13e-04 -9.25e-04]
 [ 5.97e-04 -1.34e-03  7.65e-04 -3.33e-04 -1.40e-03  1.73e-04 -9.92e-01  8.21e-04
   1.34e-03  5.78e-04  1.70e-03 -7.07e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 4.24e-06 -8.38e-07 -2.89e-07 -2.71e-06  3.41e-06  1.34e-06 -3.26e-07  5.25e-06
   1.88e-06 -3.97e-06 -1.74e-06 -4.22e-06  5.57e-06]
 [-7.68e-07  1.65e-06 -4.54e-07 -3.26e-08  3.33e-06 -8.93e-07 -1.23e-06  2.35e-06
  -1.09e-06 -3.28e-06 -1.57e-06  4.87e-06  5.01e-06]]
SymNet parameters
[-4.42e-07 -1.31e-05]
SymNet parameters
[[ 7.09e-05 -1.55e-04 -3.41e-03  5.04e-04 -3.73e-04 -3.09e-04  7.74e-05 -9.89e-01
   1.14e-04 -9.50e-05  2.39e-03  5.47e-04  3.66e-04 -1.54e-06]
 [-9.87e-01  1.67e-03  1.21e-03  6.44e-04 -1.92e-03 -1.82e-04 -7.49e-05 -8.09e-04
   9.90e-04 -2.19e-05 -1.56e-03 -4.85e-04 -1.79e-03  3.13e-06]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 9.73e-04 -5.58e-05 -7.93e-04  2.10e-04 -1.45e-04  6.84e-04  6.09e-03  3.52e-04
   1.59e-03  5.25e-02  1.35e-03  5.15e-02  9.98e-01 -7.97e-07 -9.97e-01]]
SymNet parameters
[-0.]
finally, finish this stage
iter:   372    time: 45.65
Func: 1.46e+00  |g|: 2.79e-02
stableloss: 6.28e-02   dataloss: 1.02e+00   sparseloss: 1.22e+01 momentloss: 1.22e+01
current expression:
[u00*u01, u10*v00, u20, u02, u01*u10*v00, u00, 1, u00*u11, u01**2, u10, u01*u10, v00*v11, u11*v00, u00*v10, u10*u11, u01*v10, u01, v01, u20*v00, u01*v00]
[-0.98 -0.97  0.05  0.05  0.01  0.01 -0.    0.    0.   -0.   -0.    0.    0.    0.
 -0.    0.    0.    0.    0.    0.  ]
[v00*v10, u00*v01, v02, v20, v00, u11*v00, 1, u00*u10, u01*v00, v10, u00*v11, u00, u11*v01, v01*v10, v00*v01*v10, v10*v11, u01*v01, v01*v11, u11*v10, v11]
[-0.98 -0.97  0.05  0.05  0.01  0.01 -0.   -0.    0.    0.    0.    0.   -0.    0.
  0.    0.    0.   -0.   -0.    0.  ]
block:  9
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -1.209920759879845
current stage is: block-9
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8099, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2587,  1.6531,  1.7403, 21.8169, 13.2901, 17.8270,  0.2664,  1.7122,
         1.7981, 20.2070, 18.5733, 20.3343], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward1>)
iter:     0    time: 14.60
Func: 4.64e+00  |g|: 4.48e+01
stableloss: 1.05e-01   dataloss: 3.99e+00   sparseloss: 1.22e+01 momentloss: 1.22e+01
iter:   200    time: 55.52
Func: 3.82e+00  |g|: 7.40e-01
stableloss: 1.05e-01   dataloss: 3.14e+00   sparseloss: 1.22e+01 momentloss: 1.40e+01
iter:   400    time: 72.42
Func: 3.80e+00  |g|: 1.57e-01
stableloss: 1.05e-01   dataloss: 3.16e+00   sparseloss: 1.22e+01 momentloss: 1.09e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 3.804510
         Iterations: 463
         Function evaluations: 602
         Gradient evaluations: 590
convolution moment and kernels
[[ 1.    0.    0.   -0.04 -0.01]
 [ 0.   -0.   -0.04  0.01 -0.02]
 [-0.01 -0.02  0.07 -0.04  0.01]
 [-0.08  0.05 -0.04  0.06 -0.  ]
 [-0.11  0.02 -0.08  0.01 -0.03]]
[[-0.02  0.02 -0.1   0.06 -0.03]
 [ 0.13 -0.07  0.26 -0.08  0.1 ]
 [-0.21  0.02  0.65  0.02 -0.11]
 [ 0.15  0.01  0.21  0.1   0.03]
 [-0.04  0.01 -0.09 -0.02 -0.01]]
[[ 0.00e+00  1.00e+00  0.00e+00 -9.60e-02 -1.02e-01]
 [ 0.00e+00  0.00e+00  1.25e-02 -5.83e-04  1.66e-02]
 [ 0.00e+00  6.21e-02 -1.08e-01  1.12e-01 -9.12e-02]
 [ 3.16e-03 -2.40e-02  9.53e-03 -2.23e-02  1.04e-02]
 [ 2.43e-03  7.26e-03 -3.78e-02  1.80e-02 -3.05e-02]]
[[-0.03  0.07 -0.08  0.05 -0.02]
 [-0.03  0.05 -0.03 -0.02  0.02]
 [ 0.15 -0.57 -0.44  1.15 -0.27]
 [-0.04  0.05 -0.02 -0.04  0.04]
 [-0.02  0.05 -0.05  0.04 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00  5.54e-03  8.40e-03]
 [ 1.00e+00  0.00e+00  4.85e-02 -1.12e-02 -3.03e-03]
 [ 0.00e+00 -1.77e-02 -1.26e-01 -3.96e-02 -4.73e-02]
 [-1.02e-01 -1.53e-03  8.01e-02 -1.11e-02 -3.17e-04]
 [-9.19e-02 -1.17e-02 -9.42e-02 -1.47e-02 -3.21e-02]]
[[-0.02 -0.05  0.17 -0.05 -0.02]
 [ 0.05  0.06 -0.64  0.09  0.05]
 [-0.06 -0.04 -0.32 -0.1  -0.03]
 [ 0.05 -0.05  1.12 -0.03  0.05]
 [-0.02  0.04 -0.28  0.06 -0.03]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  8.26e-03]
 [ 0.00e+00  0.00e+00  0.00e+00 -5.38e-04 -1.29e-03]
 [ 0.00e+00  0.00e+00  9.62e-03 -5.27e-03  4.43e-01]
 [ 0.00e+00 -1.43e-03  5.61e-03  4.75e-02  4.29e-03]
 [ 1.04e-01  3.70e-03  4.24e-03 -4.66e-03  1.79e-01]]
[[ 0.15 -0.59  0.94 -0.53  0.13]
 [-0.15  0.55 -1.14  0.41 -0.09]
 [-0.1   1.41 -2.04  1.47 -0.12]
 [-0.11  0.48 -1.17  0.53 -0.15]
 [ 0.13 -0.55  0.95 -0.59  0.15]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -4.89e-01]
 [ 0.00e+00  1.00e+00  0.00e+00 -5.35e-04  3.59e-03]
 [ 0.00e+00  0.00e+00 -7.34e-04  7.64e-03 -2.82e-03]
 [ 0.00e+00  2.86e-04  8.40e-04 -6.60e-04 -6.55e-03]
 [ 8.64e-03  7.74e-02 -1.90e-03 -9.31e-03  7.76e-03]]
[[ 3.00e-02 -1.66e-01  8.37e-02  6.74e-02 -6.45e-03]
 [-1.49e-01  8.83e-01 -3.16e-01 -5.13e-01  6.05e-02]
 [-3.59e-01  1.35e+00 -2.54e+00  2.11e+00 -5.11e-01]
 [-2.04e-02 -7.91e-02 -2.04e-01  3.01e-01 -3.22e-02]
 [ 9.16e-03 -2.59e-02  3.87e-02 -1.32e-02 -9.38e-05]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.18e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  3.02e-04  5.29e-04]
 [ 1.00e+00  0.00e+00  9.79e-01 -2.28e-03  4.64e-02]
 [ 0.00e+00 -2.86e-03  4.81e-03  9.07e-03  6.52e-03]
 [ 8.78e-03  2.37e-03  4.57e-01 -4.97e-03  1.13e-03]]
[[-3.21e-02  5.09e-01 -1.04e+00  5.33e-01 -4.20e-02]
 [ 9.28e-02 -9.11e-01  2.97e+00 -9.79e-01  1.21e-01]
 [-2.45e-03  3.24e-01 -3.13e+00  3.91e-01 -2.89e-02]
 [ 9.07e-02 -8.96e-01  2.92e+00 -9.21e-01  9.97e-02]
 [-3.08e-02  5.01e-01 -1.02e+00  5.03e-01 -3.12e-02]]
SymNet parameters
[[-1.61e-03 -2.00e-04 -9.88e-01  9.17e-04 -5.65e-03 -7.86e-04 -1.25e-03 -2.32e-03
   1.68e-03  4.56e-04 -1.04e-03 -1.35e-04]
 [-1.68e-04  7.06e-03  6.70e-04  3.88e-04 -9.54e-04  2.80e-05 -9.90e-01  2.22e-04
   3.63e-03 -3.23e-04  1.37e-04  9.32e-04]]
SymNet parameters
[-9.72e-04 -3.53e-05]
SymNet parameters
[[-9.87e-01 -1.12e-03  4.36e-04 -1.53e-03 -7.35e-04  1.32e-03 -2.95e-03 -6.06e-04
   1.60e-03 -2.91e-04 -2.34e-04 -6.89e-05  7.60e-03]
 [-1.70e-04 -9.95e-01 -3.47e-04 -1.75e-05  1.48e-03 -6.38e-04 -6.75e-04  2.18e-03
  -1.69e-03 -3.97e-04 -3.59e-04  4.92e-04 -9.41e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 4.63e-08 -2.77e-07 -1.23e-08  2.03e-07 -1.35e-07 -2.06e-07 -5.48e-07  2.16e-07
   5.56e-08 -1.72e-07  4.94e-07 -3.59e-07  2.54e-07  2.71e-07]
 [-6.14e-07  8.04e-08 -1.26e-07  8.38e-08  3.55e-07  5.14e-08 -5.31e-08  2.64e-07
  -1.08e-07 -2.09e-07 -1.73e-07  5.31e-07 -3.16e-07 -1.03e-07]]
SymNet parameters
[ 2.15e-07 -1.31e-08]
SymNet parameters
[[ 7.01e-03 -5.89e-04 -2.58e-05  5.41e-02 -3.35e-03  5.39e-02 -1.51e-03 -1.51e-03
  -1.32e-03  5.08e-04 -1.46e-03  4.18e-04 -9.95e-01 -1.00e+00  1.33e-07]]
SymNet parameters
[0.01]
SymNet parameters
[[-4.26e-04  8.02e-04 -1.08e-03 -4.01e-04  7.78e-04 -3.45e-04 -2.20e-03  3.72e-04
   9.91e-01 -1.66e-03  4.14e-03  9.74e-05]
 [-4.39e-05 -9.61e-04  6.87e-04  3.26e-04 -9.58e-04  1.56e-04 -9.91e-01  2.84e-03
   5.44e-03 -7.59e-04 -1.35e-06 -3.50e-07]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-1.00e-07 -2.44e-08 -2.90e-08 -1.23e-07  4.39e-09  1.52e-07  2.52e-09 -3.72e-08
   1.79e-07 -6.14e-08 -5.80e-09 -1.83e-07 -3.48e-08]
 [-7.51e-08 -8.56e-08 -1.09e-07  6.49e-08  7.34e-09 -1.93e-07 -2.40e-07 -1.20e-07
   2.56e-07  9.68e-09 -1.58e-07  1.63e-08  1.26e-08]]
SymNet parameters
[2.47e-08 1.69e-07]
SymNet parameters
[[-9.95e-04 -2.07e-03 -1.03e-03 -2.88e-04  4.59e-05 -3.77e-04  3.31e-04 -9.91e-01
  -9.40e-04 -6.10e-04  1.05e-04 -2.03e-04 -8.03e-04 -4.50e-07]
 [-9.90e-01  6.60e-04  3.76e-03 -2.85e-04 -3.67e-04  3.27e-04 -3.23e-04 -5.60e-04
   3.05e-04  1.60e-05 -6.34e-05  3.21e-04 -1.07e-03  2.46e-08]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-2.84e-04  9.51e-04 -1.95e-03  6.78e-04 -4.14e-04  6.87e-04  1.07e-02  9.61e-04
   3.95e-04  5.50e-02 -4.59e-03  5.29e-02  1.00e+00 -1.35e-07 -9.97e-01]]
SymNet parameters
[0.]
finally, finish this stage
iter:   463    time: 30.04
Func: 3.80e+00  |g|: 3.05e-03
stableloss: 1.05e-01   dataloss: 3.16e+00   sparseloss: 1.22e+01 momentloss: 1.09e+01
current expression:
[u00*u01, u10*v00, u02, u20, u00, u01*u10*v00, u01*u10, 1, u11*v00, u10*v10, u11, u01*v00, v00, v00*v01, u00*v00, u00*v01, u00*v10, v00*v10, u01*v10, u01*u02]
[-0.99 -0.97  0.05  0.05  0.01  0.01  0.01  0.01 -0.01  0.   -0.   -0.   -0.   -0.
 -0.    0.   -0.    0.    0.   -0.  ]
[v00*v10, u00*v01, v02, v20, v00, v10**2, v11, v00*v11, u10*v01, v01*v10, v00**2, u00*u01, u10, v01, v00*v02, 1, u10*v00, v00*v01*v10, u00*u10, u00**2]
[-0.98 -0.98  0.06  0.05  0.01  0.01 -0.   -0.    0.    0.    0.   -0.   -0.    0.
  0.    0.    0.    0.   -0.   -0.  ]
block:  12
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  0.8735277606301041
current stage is: block-12
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8807, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2435,  1.7101,  1.5669, 24.5281, 15.0449, 12.3968,  0.2546,  1.6478,
         1.5438, 20.4082, 11.3401, 14.1757], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward1>)
iter:     0    time: 15.37
Func: 5.98e+00  |g|: 1.18e+02
stableloss: 1.06e-01   dataloss: 5.11e+00   sparseloss: 1.22e+01 momentloss: 1.09e+01
iter:   200    time: 74.38
Func: 5.04e+00  |g|: 8.38e-01
stableloss: 1.03e-01   dataloss: 4.18e+00   sparseloss: 1.22e+01 momentloss: 1.07e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 5.040572
         Iterations: 298
         Function evaluations: 389
         Gradient evaluations: 375
convolution moment and kernels
[[ 1.    0.   -0.    0.03 -0.02]
 [ 0.    0.   -0.01  0.01 -0.03]
 [ 0.01  0.    0.06 -0.04  0.  ]
 [-0.05 -0.01 -0.03  0.01 -0.03]
 [-0.03 -0.02 -0.01 -0.02 -0.01]]
[[ 0.01 -0.04  0.04 -0.02 -0.  ]
 [ 0.01  0.03 -0.04  0.07  0.02]
 [-0.07  0.06  0.96 -0.12 -0.03]
 [ 0.03  0.    0.04  0.07  0.03]
 [-0.01  0.04 -0.09  0.03 -0.02]]
[[ 0.    1.    0.   -0.11 -0.11]
 [ 0.    0.   -0.05 -0.01 -0.05]
 [ 0.    0.06 -0.03  0.09 -0.07]
 [ 0.   -0.01 -0.06 -0.03 -0.04]
 [-0.    0.01 -0.01  0.01 -0.02]]
[[-0.01  0.03 -0.04  0.01  0.01]
 [-0.04  0.05  0.   -0.02  0.01]
 [ 0.15 -0.6  -0.45  1.16 -0.27]
 [-0.04  0.08 -0.03 -0.04  0.04]
 [-0.02  0.08 -0.11  0.09 -0.03]]
[[ 0.    0.    0.    0.01 -0.  ]
 [ 1.    0.    0.05  0.04  0.02]
 [ 0.   -0.02 -0.07  0.01 -0.01]
 [-0.11  0.02  0.06  0.02  0.01]
 [-0.1  -0.03 -0.08 -0.01 -0.02]]
[[-0.01 -0.03  0.15 -0.05 -0.02]
 [ 0.03  0.05 -0.62  0.1   0.06]
 [-0.05  0.01 -0.46 -0.   -0.11]
 [ 0.04 -0.04  1.15 -0.06  0.09]
 [-0.02  0.03 -0.24  0.01 -0.02]]
[[ 0.    0.    1.    0.   -0.47]
 [ 0.    0.    0.   -0.   -0.01]
 [ 0.    0.    0.11 -0.04  0.28]
 [ 0.   -0.01 -0.14 -0.   -0.  ]
 [ 0.    0.04  0.01 -0.    0.13]]
[[ 0.1  -0.37  0.47 -0.3   0.1 ]
 [-0.13  0.6  -0.79  0.43 -0.14]
 [-0.49  2.57 -4.34  2.75 -0.46]
 [-0.15  0.97 -1.5   0.83 -0.17]
 [ 0.11 -0.54  0.81 -0.49  0.11]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  7.80e-02]
 [ 0.00e+00  1.00e+00  0.00e+00 -6.96e-04 -5.34e-03]
 [ 0.00e+00  0.00e+00 -5.52e-03  6.86e-03  4.73e-02]
 [ 0.00e+00  1.54e-03  3.08e-02  8.56e-04 -2.30e-03]
 [ 1.46e-01  9.22e-02  3.34e-03 -9.17e-04 -4.52e-03]]
[[ 0.01 -0.1   0.13  0.13 -0.02]
 [-0.01  0.39 -0.11 -1.02  0.17]
 [-0.01 -0.08  0.38  0.71 -0.13]
 [ 0.1  -0.57  0.03 -0.2   0.07]
 [-0.01  0.05  0.04  0.07 -0.01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  6.34e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -3.23e-03  8.15e-02]
 [ 1.00e+00  0.00e+00  3.59e-01 -8.17e-03  7.07e-03]
 [ 0.00e+00 -5.79e-02 -5.54e-03 -5.20e-04 -1.22e-02]
 [ 2.30e-01 -5.92e-04  3.73e-01  2.27e-03  7.33e-03]]
[[-8.28e-03  3.66e-01 -6.00e-01  3.98e-01 -1.01e-02]
 [ 2.97e-03 -9.94e-01  2.44e+00 -1.03e+00 -6.09e-03]
 [ 5.31e-01 -8.19e-01 -5.10e-01 -8.91e-01  5.66e-01]
 [ 1.46e-01 -1.59e+00  3.21e+00 -1.47e+00  1.15e-01]
 [-3.85e-02  5.01e-01 -7.41e-01  4.56e-01 -3.06e-02]]
SymNet parameters
[[ 8.04e-04  1.57e-03 -9.88e-01 -8.45e-04 -6.04e-03 -3.10e-03  7.89e-04 -1.29e-03
  -3.90e-04 -2.81e-04  1.45e-04  3.31e-04]
 [-2.89e-04  2.93e-04  4.74e-04 -5.21e-05  2.04e-04  8.05e-05 -9.90e-01 -6.17e-03
  -3.03e-03 -2.95e-04  1.04e-04 -1.64e-04]]
SymNet parameters
[ 5.65e-05 -2.51e-04]
SymNet parameters
[[-9.91e-01 -5.31e-03  1.80e-04 -1.32e-03  2.51e-04  8.61e-04 -5.66e-04  1.36e-03
  -3.79e-04  4.63e-04  9.82e-05 -1.35e-04  5.08e-03]
 [ 3.11e-04 -9.84e-01  2.14e-04 -5.58e-04 -1.05e-02 -1.29e-03  6.46e-04 -2.35e-03
   2.71e-04  4.97e-04  1.31e-03  2.67e-04 -4.29e-04]]
SymNet parameters
[0.   0.01]
SymNet parameters
[[-3.09e-07 -1.24e-06 -1.54e-07 -4.18e-06 -2.97e-06  3.22e-07  3.01e-06 -1.37e-06
   2.05e-06  2.56e-06  1.65e-06 -1.30e-06  1.54e-06  1.85e-06]
 [ 1.24e-06  1.43e-06  8.58e-07 -6.80e-07  6.59e-07  1.60e-06  2.43e-07 -1.59e-06
  -1.54e-06 -3.30e-06 -3.02e-06  7.38e-07 -8.40e-07 -1.62e-08]]
SymNet parameters
[-1.17e-06  1.37e-07]
SymNet parameters
[[ 1.65e-03  5.74e-04 -2.42e-04  5.11e-02 -6.40e-03  5.30e-02  6.29e-05 -1.80e-03
  -4.07e-04  5.17e-04  6.04e-04 -5.87e-04 -9.95e-01 -1.01e+00 -2.56e-08]]
SymNet parameters
[-0.]
SymNet parameters
[[ 2.92e-04 -3.85e-04 -1.63e-03  2.83e-04  1.36e-03 -2.72e-04 -2.95e-04  1.77e-04
   9.87e-01  9.55e-04  7.88e-03  2.33e-03]
 [-1.68e-04 -7.41e-04  2.85e-03 -2.75e-04  3.34e-04 -6.87e-04 -9.91e-01 -7.77e-04
  -2.81e-03 -4.70e-04  7.41e-05 -1.45e-03]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[ 2.83e-06  4.23e-06  3.85e-06  2.23e-07 -2.74e-06 -7.24e-07  2.28e-06  1.21e-06
   2.98e-06  1.48e-06  8.06e-07  1.01e-06  4.74e-07]
 [-2.44e-06 -5.39e-07  1.57e-06  2.37e-07 -3.40e-06  3.50e-06 -1.17e-06 -5.42e-06
  -3.06e-06 -6.36e-07 -3.41e-06 -1.76e-06  6.35e-06]]
SymNet parameters
[-8.41e-07 -3.13e-07]
SymNet parameters
[[ 1.51e-03 -3.90e-04 -2.69e-03  5.94e-04  2.39e-04  5.29e-04 -3.61e-04 -9.86e-01
   3.89e-05  2.72e-04 -9.95e-03 -8.11e-04 -3.88e-04 -2.23e-06]
 [-9.85e-01 -6.57e-03 -2.97e-03 -3.31e-04 -5.74e-05  9.01e-07 -1.73e-04  4.27e-04
  -5.25e-03  2.24e-04  6.91e-05 -4.52e-05  3.23e-04  2.25e-06]]
SymNet parameters
[0. 0.]
SymNet parameters
[[ 2.98e-04  1.55e-03  7.67e-04  1.84e-05 -6.42e-04 -1.33e-04  3.91e-03  9.60e-04
  -9.97e-04  5.27e-02 -7.07e-03  5.29e-02  1.00e+00 -3.67e-07 -1.00e+00]]
SymNet parameters
[0.]
finally, finish this stage
iter:   298    time: 58.01
Func: 5.04e+00  |g|: 3.96e-02
stableloss: 1.03e-01   dataloss: 4.18e+00   sparseloss: 1.22e+01 momentloss: 1.09e+01
current expression:
[u00*u01, u10*v00, u20, u02, u00*u11, u00, u11, u10*v01, u11*v00, u01**2, u01*u10*v00, u20*v00, u10*v10, u00*v01, 1, v01, u00*v00, u01*v01, u01*u02, u00*v11]
[-0.98 -0.97  0.05  0.05 -0.01  0.01 -0.01 -0.01 -0.01 -0.01  0.   -0.   -0.   -0.
 -0.   -0.    0.    0.   -0.    0.  ]
[v00*v10, u00*v01, v20, v02, u00*v11, v00*v11, v00, v11, u01*v01, v01*v10, v10, u10*v01, u10*v10, v10**2, u00*u10, 1, v00*v20, v01, u10*v00, u01]
[-0.98 -0.97  0.05  0.05 -0.01 -0.01  0.01 -0.01 -0.01 -0.01 -0.01 -0.    0.   -0.
 -0.    0.   -0.    0.    0.    0.  ]
block:  15
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -0.9244099212002335
current stage is: block-15
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8929, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2446,  1.6094,  1.5645, 39.9471,  9.7417, 15.0255,  0.2508,  1.5610,
         1.7039, 31.3163, 10.4778, 14.2704], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward1>)
iter:     0    time: 16.24
Func: 1.49e+01  |g|: 3.52e+02
stableloss: 1.80e-01   dataloss: 1.38e+01   sparseloss: 1.22e+01 momentloss: 1.09e+01
iter:   200    time: 91.59
Func: 1.20e+01  |g|: 7.81e+00
stableloss: 1.91e-01   dataloss: 1.08e+01   sparseloss: 1.38e+01 momentloss: 1.31e+01
iter:   400    time: 90.98
Func: 1.18e+01  |g|: 1.07e+00
stableloss: 1.91e-01   dataloss: 1.05e+01   sparseloss: 1.50e+01 momentloss: 1.55e+01
iter:   600    time: 88.32
Func: 1.18e+01  |g|: 3.04e-01
stableloss: 1.91e-01   dataloss: 1.05e+01   sparseloss: 1.49e+01 momentloss: 1.54e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 11.819437
         Iterations: 743
         Function evaluations: 829
         Gradient evaluations: 814
convolution moment and kernels
[[ 1.    0.    0.03 -0.   -0.01]
 [ 0.    0.   -0.05 -0.07 -0.01]
 [-0.02  0.06  0.03  0.01 -0.02]
 [-0.06 -0.05 -0.13 -0.1  -0.05]
 [-0.07  0.   -0.01  0.03 -0.  ]]
[[-0.02  0.03 -0.03 -0.08  0.05]
 [ 0.03  0.02 -0.08  0.35 -0.13]
 [-0.07  0.07  0.96 -0.41  0.1 ]
 [ 0.07 -0.06  0.11  0.2  -0.01]
 [-0.02  0.02 -0.08  0.01 -0.03]]
[[ 0.    1.    0.   -0.1  -0.1 ]
 [ 0.    0.    0.03  0.02  0.03]
 [ 0.    0.05 -0.12  0.09 -0.11]
 [-0.01 -0.02  0.03  0.01  0.02]
 [ 0.   -0.   -0.05  0.01 -0.04]]
[[-3.51e-02  8.18e-02 -8.72e-02  8.01e-02 -3.39e-02]
 [-1.25e-02  2.71e-02 -6.17e-02 -9.01e-03  3.89e-02]
 [ 1.28e-01 -5.65e-01 -3.44e-01  1.06e+00 -2.58e-01]
 [-1.49e-02 -1.01e-03 -2.39e-02 -9.32e-04  3.46e-02]
 [-2.70e-02  7.23e-02 -6.05e-02  2.82e-02 -1.28e-02]]
[[ 0.    0.    0.   -0.    0.  ]
 [ 1.    0.    0.07 -0.01  0.02]
 [ 0.    0.   -0.06  0.03 -0.01]
 [-0.1  -0.01  0.09 -0.01  0.03]
 [-0.1  -0.01 -0.08  0.01 -0.02]]
[[-0.03 -0.01  0.12 -0.03 -0.02]
 [ 0.06  0.03 -0.56  0.04  0.06]
 [-0.06 -0.02 -0.4  -0.04 -0.08]
 [ 0.04 -0.03  1.09  0.02  0.05]
 [-0.01  0.01 -0.22 -0.01 -0.01]]
[[ 0.    0.    1.    0.    0.5 ]
 [ 0.    0.    0.   -0.01  0.14]
 [ 0.    0.    0.01  0.01  0.18]
 [ 0.   -0.09  0.01 -0.   -0.01]
 [-0.01 -1.23  0.38  0.01  0.19]]
[[ 5.87e-02  5.30e-01  2.07e-01 -1.07e+00  2.64e-01]
 [-8.89e-02 -2.75e+00  3.63e-02  3.74e+00 -9.13e-01]
 [ 2.88e-01  4.55e+00 -1.06e+00 -5.38e+00  1.55e+00]
 [ 1.40e-01 -3.73e+00  1.31e+00  3.03e+00 -7.23e-01]
 [ 1.76e-02  7.32e-01 -4.11e-03 -9.91e-01  2.38e-01]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  9.46e-02]
 [ 0.00e+00  1.00e+00  0.00e+00 -2.51e-03  6.53e-03]
 [ 0.00e+00  0.00e+00 -3.19e-01 -5.01e-01 -7.52e-02]
 [ 0.00e+00  2.45e-03  1.63e-03  7.08e-03 -8.98e-04]
 [ 1.61e-01  4.70e-03  7.42e-03 -1.23e-01  4.58e-04]]
[[ 0.05 -0.13  0.12  0.16 -0.04]
 [-0.04  0.11 -0.15 -0.46 -0.1 ]
 [-0.04  0.48  0.57 -0.51  0.47]
 [ 0.09 -0.84 -0.08  0.39 -0.2 ]
 [ 0.04 -0.    0.11  0.05 -0.03]]
[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.81e-01]
 [ 0.00e+00  0.00e+00  0.00e+00 -3.06e-02 -1.55e-01]
 [ 1.00e+00  0.00e+00  8.46e-01 -6.55e-02  3.13e-01]
 [ 0.00e+00 -4.73e-03 -4.88e-03  1.27e-03  8.94e-04]
 [ 2.25e-01  1.24e+00  2.01e-01 -6.75e-03  4.14e-02]]
[[ 9.64e-02 -6.62e-01 -1.79e-01  1.00e+00 -1.15e-01]
 [-6.38e-02  2.27e+00  1.77e+00 -4.26e+00  7.23e-01]
 [-2.83e-01 -2.38e+00 -4.37e+00  7.28e+00 -1.40e+00]
 [-2.51e-01  3.06e+00  4.98e-01 -3.37e+00  4.92e-01]
 [ 1.20e-01 -7.66e-01 -6.26e-03  8.77e-01 -8.39e-02]]
SymNet parameters
[[-8.81e-05  5.41e-01 -6.63e-01 -8.33e-04  2.01e-03  6.32e-04 -4.42e-04  1.48e-04
   1.81e-03  6.17e-04 -5.18e-04 -9.36e-04]
 [ 4.50e-01 -2.49e-04 -2.71e-03 -2.05e-04 -4.29e-04  5.26e-04 -8.51e-01  8.75e-04
   3.54e-03  5.27e-04  1.03e-03  1.73e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[-6.59e-01  1.26e-03  4.66e-03  1.20e-03  9.43e-04 -7.18e-04 -5.34e-01  6.88e-04
   2.47e-03  5.66e-04  1.08e-03  3.15e-04  8.87e-03]
 [ 1.59e-03 -7.96e-01 -4.16e-01  1.52e-03  6.04e-03  1.30e-03 -5.04e-05 -2.46e-03
  -7.42e-04  4.70e-04  3.43e-06 -4.14e-04  4.99e-04]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-1.02e-06 -1.34e-06  6.17e-08  4.45e-06 -1.07e-06  2.80e-07 -2.60e-06  4.66e-07
  -3.20e-07 -1.90e-07  8.60e-07  7.75e-07 -2.43e-07 -8.31e-07]
 [ 5.24e-08  9.46e-07 -4.47e-06  5.09e-07  3.82e-07  8.47e-07 -1.65e-06 -1.98e-06
   9.31e-08 -2.10e-07  2.26e-06  2.78e-07 -2.45e-07 -4.50e-07]]
SymNet parameters
[ 2.89e-06 -1.58e-06]
SymNet parameters
[[ 6.09e-03  2.14e-04  3.82e-04  5.36e-02 -1.04e-02  5.53e-02 -1.08e-04  3.81e-04
   2.16e-03 -6.43e-04 -1.07e-03 -3.15e-04 -1.21e+00 -1.31e+00  1.09e-06]]
SymNet parameters
[-0.]
SymNet parameters
[[ 1.11e-04 -2.36e-03 -8.45e-05 -1.55e-03  1.10e-03  1.40e-03  8.84e-04  2.68e-01
   8.98e-01 -8.05e-04 -6.72e-03 -9.71e-04]
 [-4.29e-01 -7.36e-04  4.32e-03  7.01e-04  1.46e-04  3.06e-04 -7.67e-01  3.81e-03
   1.84e-03  6.93e-04  1.89e-03 -2.39e-04]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 3.55e-07 -1.01e-06  1.80e-07 -4.09e-07 -1.36e-06  1.80e-08  6.60e-07 -1.60e-06
   2.18e-07 -7.20e-07  1.05e-06 -1.75e-06 -1.02e-06]
 [-1.13e-06 -2.74e-07 -1.03e-06  9.80e-07  2.10e-06 -1.09e-06  1.32e-06 -1.48e-07
   5.25e-07 -1.64e-06  3.74e-07  4.55e-07  1.08e-07]]
SymNet parameters
[-2.34e-07 -1.18e-07]
SymNet parameters
[[ 1.54e-03 -5.83e-04  4.73e-04 -1.29e-03 -1.56e-04  1.18e-03  8.88e-04 -7.62e-01
   4.31e-01  2.00e-03 -2.96e-04  2.94e-05  9.28e-06 -1.02e-06]
 [-9.39e-01 -2.95e-04  5.55e-03  8.18e-04  1.34e-03 -6.98e-05  2.81e-01 -1.61e-03
   6.71e-04 -4.78e-04 -7.18e-04  7.24e-04  1.47e-02  6.55e-07]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-5.91e-04 -2.51e-03  9.51e-04 -1.34e-04 -1.96e-03 -1.71e-04  2.68e-03 -5.75e-04
   1.15e-03  5.40e-02 -1.04e-02  5.48e-02  1.22e+00 -7.14e-08 -1.17e+00]]
SymNet parameters
[0.]
finally, finish this stage
iter:   743    time: 84.07
Func: 1.18e+01  |g|: 3.29e-01
stableloss: 1.91e-01   dataloss: 1.05e+01   sparseloss: 1.49e+01 momentloss: 1.55e+01
current expression:
[u00*u01, u10*v00, u20, u02, u11, u00, u01*u10, u11*v00, u01**2*v00, u10*v10, u00*u11, u01*u10*v00, u10**2*v00, u00*u01**2, u00*v01, v10, u01*v00, 1, u00*u02, u00*v10]
[-0.98 -0.97  0.06  0.05 -0.01  0.01  0.01  0.01 -0.    0.    0.    0.    0.    0.
 -0.    0.   -0.   -0.    0.   -0.  ]
[v00*v10, u00*v01, v20, v02, v11, v00*v01*v10, v00*v11, u10*v01, v01*v10, v00*v10**2, u00*v01*v10, v00, u00*v11, u00, 1, u00*v10**2, v10, v00*v01**2, u00*v02, u01]
[-0.98 -0.98  0.05  0.05 -0.01 -0.01  0.01  0.01  0.01  0.01 -0.    0.    0.   -0.
  0.    0.    0.   -0.    0.   -0.  ]
block:  18
name:  burgers-2-upwind-sparse0.005-noise0.001
device:  cuda:0
generate a random number to check random seed:  -1.2794983774550817
current stage is: block-18
u_obs shape: batchsize x channelNum x xgridsize x ygridsize
torch.Size([28, 2, 32, 32])
u_obs.abs().max()
tensor(3.8173, device='cuda:0', dtype=torch.float64)
u_obs variance
tensor([ 0.2532,  1.7897,  1.5028, 22.7415, 10.0113, 24.0046,  0.2569,  1.6195,
         1.7362, 29.6951, 10.6144, 31.9647], device='cuda:0',
       dtype=torch.float64, grad_fn=<MeanBackward1>)
iter:     0    time: 19.40
Func: 2.51e+01  |g|: 1.00e+03
stableloss: 2.09e-01   dataloss: 2.35e+01   sparseloss: 1.49e+01 momentloss: 1.55e+01
iter:   200    time: 105.79
Func: 1.74e+01  |g|: 2.41e+01
stableloss: 2.24e-01   dataloss: 1.56e+01   sparseloss: 1.53e+01 momentloss: 1.89e+01
iter:   400    time: 104.09
Func: 1.67e+01  |g|: 5.27e+00
stableloss: 2.21e-01   dataloss: 1.47e+01   sparseloss: 1.87e+01 momentloss: 1.96e+01
iter:   600    time: 103.86
Func: 1.66e+01  |g|: 1.42e+01
stableloss: 2.20e-01   dataloss: 1.46e+01   sparseloss: 1.79e+01 momentloss: 1.95e+01
iter:   800    time: 104.40
Func: 1.64e+01  |g|: 7.69e+00
stableloss: 2.15e-01   dataloss: 1.44e+01   sparseloss: 1.70e+01 momentloss: 2.21e+01
iter:  1000    time: 103.13
Func: 1.63e+01  |g|: 3.59e+00
stableloss: 2.13e-01   dataloss: 1.44e+01   sparseloss: 1.69e+01 momentloss: 2.26e+01
iter:  1200    time: 104.94
Func: 1.63e+01  |g|: 5.59e+00
stableloss: 2.13e-01   dataloss: 1.44e+01   sparseloss: 1.66e+01 momentloss: 2.26e+01
iter:  1400    time: 106.32
Func: 1.63e+01  |g|: 1.60e+00
stableloss: 2.13e-01   dataloss: 1.44e+01   sparseloss: 1.66e+01 momentloss: 2.21e+01
iter:  1600    time: 106.64
Func: 1.63e+01  |g|: 2.45e+00
stableloss: 2.13e-01   dataloss: 1.44e+01   sparseloss: 1.65e+01 momentloss: 2.23e+01
Warning: Desired error not necessarily achieved due to precision loss.
         Current function value: 16.253754
         Iterations: 1628
         Function evaluations: 1705
         Gradient evaluations: 1692
convolution moment and kernels
[[ 1.00e+00  0.00e+00 -7.60e-04  3.62e-02 -3.11e-02]
 [ 0.00e+00 -8.18e-04  3.72e-02 -2.15e-02  2.77e-02]
 [-6.01e-03  4.49e-03  6.92e-02  4.35e-02  1.24e-03]
 [-4.39e-02 -1.88e-03 -5.64e-03  1.38e-02  1.62e-02]
 [-3.29e-02  3.44e-02  6.07e-03  4.02e-02 -1.04e-02]]
[[-0.03  0.08 -0.12  0.07 -0.01]
 [ 0.06 -0.1   0.23 -0.13  0.01]
 [-0.15  0.24  0.58  0.16 -0.02]
 [ 0.09 -0.1   0.19 -0.01 -0.02]
 [-0.02  0.03 -0.07 -0.01  0.02]]
[[ 0.    1.    0.   -0.12 -0.1 ]
 [ 0.    0.    0.   -0.01 -0.01]
 [ 0.    0.04 -0.11  0.07 -0.09]
 [ 0.01 -0.    0.03 -0.    0.01]
 [ 0.    0.01 -0.05  0.01 -0.04]]
[[-0.03  0.07 -0.09  0.08 -0.03]
 [ 0.01 -0.05  0.11 -0.16  0.08]
 [ 0.1  -0.47 -0.59  1.29 -0.31]
 [-0.02  0.01  0.03 -0.09  0.04]
 [-0.02  0.06 -0.07  0.06 -0.02]]
[[ 0.00e+00  0.00e+00  0.00e+00 -5.05e-03 -3.26e-03]
 [ 1.00e+00  0.00e+00  4.50e-02  5.66e-04  2.49e-02]
 [ 0.00e+00 -1.84e-02 -9.86e-02  9.60e-03 -2.14e-02]
 [-1.19e-01 -9.78e-03  1.60e-02 -2.39e-04 -8.25e-03]
 [-1.07e-01 -1.68e-02 -1.08e-01  6.00e-03 -3.36e-02]]
[[-0.02 -0.02  0.14 -0.05 -0.01]
 [ 0.07  0.03 -0.59  0.09  0.05]
 [-0.13  0.11 -0.54  0.02 -0.11]
 [ 0.11 -0.15  1.21 -0.06  0.09]
 [-0.03  0.04 -0.24  0.01 -0.03]]
[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  6.04e-01]
 [ 0.00e+00  0.00e+00  0.00e+00  5.27e-04  1.81e-01]
 [ 0.00e+00  0.00e+00  2.29e-01 -5.28e-03  3.90e-01]
 [ 0.00e+00  8.35e-03 -1.45e-01 -1.09e-01  6.27e-03]
 [-5.44e-01 -1.47e-02  6.65e-03  3.83e-03  1.17e-01]]
[[ 0.06 -0.23 -0.11 -0.38  0.12]
 [-0.    0.25  1.46  0.61 -0.15]
 [ 0.27 -0.61 -2.44 -0.8   0.32]
 [ 0.09 -0.04  2.11 -0.15  0.17]
 [ 0.1  -0.45  0.1  -0.36  0.06]]
[[ 0.    0.    0.    0.   -0.26]
 [ 0.    1.    0.    0.45 -0.83]
 [ 0.    0.    0.13  2.37  0.01]
 [ 0.    0.68  0.85  0.75  0.04]
 [-0.15 -2.02 -0.1   0.41 -0.  ]]
[[-0.18  1.06  0.61 -1.72  0.08]
 [ 0.19 -4.03  0.82  2.82  0.82]
 [ 0.49  4.65 -0.51 -4.59 -0.96]
 [-0.4  -2.43 -2.07  6.2  -0.68]
 [-0.37  1.81 -0.43 -1.65  0.48]]
[[ 0.    0.    0.    0.   -0.41]
 [ 0.    0.    0.   -0.05 -0.04]
 [ 1.    0.    0.64 -0.4   0.07]
 [ 0.   -0.07  0.05 -0.01  0.01]
 [ 0.73  0.29  0.58 -0.12  0.12]]
[[ 1.37e-01 -7.25e-02  4.50e-02  5.34e-01 -1.23e-03]
 [-3.29e-01  3.66e-01 -2.29e-01 -1.21e+00 -1.67e-01]
 [ 2.65e-03  9.69e-01 -1.85e+00  2.72e+00  1.17e-02]
 [-3.63e-01  4.04e-01 -4.55e-01 -8.84e-01 -2.71e-01]
 [ 1.44e-01 -2.97e-02  3.10e-02  4.79e-01  1.80e-02]]
SymNet parameters
[[ 1.72e-03 -6.39e-01 -6.90e-01  8.26e-04  1.39e-03 -6.13e-04 -1.54e-03 -5.60e-04
  -3.44e-04 -1.09e-03  2.49e-03  3.51e-04]
 [-3.57e-01  3.18e-02 -1.34e-02  3.16e-04  2.76e-04 -1.68e-03 -8.22e-01  3.61e-04
  -1.81e-04 -7.56e-04 -4.93e-04  1.70e-03]]
SymNet parameters
[0. 0.]
SymNet parameters
[[-6.27e-01 -2.10e-02 -2.26e-02  1.67e-03 -5.37e-04 -7.85e-04  5.80e-01  5.34e-04
  -3.06e-04  7.62e-04 -1.63e-04 -8.05e-04  9.76e-03]
 [ 1.48e-03 -8.90e-01  3.81e-01  1.19e-03 -1.02e-03  7.30e-04 -4.71e-04 -9.74e-04
  -7.01e-04 -1.24e-03  4.46e-04  2.36e-03  5.43e-03]]
SymNet parameters
[-0.    0.01]
SymNet parameters
[[ 1.74e-07 -9.80e-07  9.02e-07 -5.26e-07  4.99e-07  2.76e-07  6.49e-07 -1.03e-06
  -9.76e-08 -1.48e-07 -5.00e-07 -7.99e-07  2.77e-07 -6.27e-07]
 [-2.10e-08  5.91e-07 -1.31e-07 -2.16e-07  4.62e-08  6.35e-07 -7.27e-07  3.47e-07
  -9.27e-07  1.87e-07 -3.98e-07 -5.54e-07 -5.95e-07 -5.73e-07]]
SymNet parameters
[ 1.49e-06 -3.59e-07]
SymNet parameters
[[ 9.30e-04  1.27e-04  2.66e-03  5.21e-02  8.45e-03  5.33e-02 -2.91e-04  1.94e-03
  -7.29e-04  1.16e-04 -8.66e-04  2.71e-04 -1.22e+00 -1.25e+00 -4.81e-07]]
SymNet parameters
[-0.]
SymNet parameters
[[-3.45e-01  9.51e-04  2.00e-03 -5.80e-04 -2.90e-03  1.81e-03  1.49e-01  2.88e-01
   6.71e-01 -8.61e-05 -2.53e-04  6.42e-05]
 [-2.47e-01  6.97e-04  2.31e-03  5.35e-04  8.22e-04 -1.22e-03 -6.60e-01  3.39e-01
  -1.27e-01 -2.17e-03  4.54e-04  2.68e-03]]
SymNet parameters
[-0. -0.]
SymNet parameters
[[-2.54e-07 -8.68e-07 -4.96e-07  5.09e-07 -1.86e-07  6.11e-07 -1.91e-07  7.51e-07
   2.27e-07 -8.32e-08 -3.88e-08 -8.32e-09  2.63e-09]
 [-2.57e-07 -2.68e-07  8.75e-07 -5.08e-07 -5.15e-07  2.23e-07 -1.18e-06  2.22e-07
   3.12e-07 -1.89e-07 -6.79e-07 -1.18e-06  1.10e-08]]
SymNet parameters
[ 2.48e-07 -4.32e-07]
SymNet parameters
[[-1.33e-01  5.40e-04 -1.38e-03 -1.21e-03 -4.54e-04  9.64e-04 -3.53e-01 -6.89e-01
   2.60e-01 -2.47e-04  4.52e-04  9.24e-04 -1.85e-02  2.24e-07]
 [-6.80e-01 -8.23e-04  2.08e-03  1.12e-03 -3.91e-05 -9.25e-04  2.95e-01 -1.51e-01
  -3.57e-01  7.78e-04  2.06e-04 -1.05e-03  3.82e-03 -4.83e-07]]
SymNet parameters
[-0.  0.]
SymNet parameters
[[ 6.48e-04 -8.40e-04  6.01e-05  4.26e-04  3.34e-04 -8.16e-04  9.43e-04  5.36e-05
  -8.94e-04  5.32e-02  7.22e-03  5.04e-02  1.50e+00  6.99e-07 -1.41e+00]]
SymNet parameters
[-0.]
finally, finish this stage
iter:  1628    time: 34.71
Func: 1.63e+01  |g|: 2.34e-01
stableloss: 2.13e-01   dataloss: 1.44e+01   sparseloss: 1.65e+01 momentloss: 2.23e+01
current expression:
[u00*u01, u10*v00, u20, u02, u11, u00, u01**2*v00, v00, u10, u01*v00, 1, u01*u10*v00, u10**2*v00, u00*u01**2, u10*v00**2, u00*u10, v00*v11, u01*u20, u11*v00, u01*u02]
[-0.98 -0.97  0.05  0.05  0.01  0.01  0.01 -0.01  0.    0.   -0.    0.   -0.    0.
 -0.   -0.    0.   -0.    0.    0.  ]
[v00*v10, u00*v01, v02, v20, v11, v01*v10, v00, u00*v00*v10, v00*v10**2, u10*v01, v10*v20, u00*v00**2, v00*v01*v10, v00**2*v10, u11*v00, u00**2*v01, u20*v00, u00*v00, u00*u10, v10**2]
[-0.98 -0.97  0.05  0.05  0.01 -0.01  0.01  0.    0.    0.    0.    0.    0.   -0.
  0.    0.   -0.    0.   -0.    0.  ]
u_obs.abs().max()
tensor(3.9499, device='cuda:0', dtype=torch.float64)
model(u_obs[0],T=50*dt).abs().max()
tensor(3.4177, device='cuda:0', dtype=torch.float64)
model(u_obs[0],T=100*dt).abs().max()
tensor(2.8505, device='cuda:0', dtype=torch.float64)
